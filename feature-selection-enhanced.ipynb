{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b422771",
   "metadata": {},
   "source": [
    "# Feature Selection & Model Comparison\n",
    "\n",
    "## Objective:\n",
    "1. Apply multiple feature selection algorithms to identify the most influential features\n",
    "2. Compare model performance with all features vs selected features\n",
    "3. Evaluate training time reduction\n",
    "\n",
    "## Feature Selection Algorithms:\n",
    "- **Boruta** - Wrapper method using Random Forest\n",
    "- **RFE (Recursive Feature Elimination)** - Recursive elimination\n",
    "- **Correlation-based Feature Selection** - Filter method\n",
    "- **Ensemble Feature Importance** - Ensemble-based selection\n",
    "\n",
    "## Models:\n",
    "- LightGBM\n",
    "- XGBClassifier\n",
    "- CatBoost\n",
    "\n",
    "## Evaluation Metrics:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- MCC (Matthews Correlation Coefficient)\n",
    "- Training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292985f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boruta in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: catboost in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boruta) (1.16.3)\n",
      "Requirement already satisfied: graphviz in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (3.10.6)\n",
      "Requirement already satisfied: plotly in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (6.5.2)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly->catboost) (2.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not available\n",
    "!pip install boruta lightgbm xgboost catboost scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b7cca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, matthews_corrcoef, classification_report\n",
    ")\n",
    "\n",
    "# Models\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Boruta\n",
    "from boruta import BorutaPy\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aceb6f3",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3100bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATASET INFORMATION\n",
      "======================================================================\n",
      "Number of Rows: 235795\n",
      "Number of Columns: 63\n",
      "\n",
      "Column Names:\n",
      "  1. FILENAME\n",
      "  2. URL\n",
      "  3. URLLength\n",
      "  4. Domain\n",
      "  5. DomainLength\n",
      "  6. IsDomainIP\n",
      "  7. TLD\n",
      "  8. URLSimilarityIndex\n",
      "  9. CharContinuationRate\n",
      "  10. TLDLegitimateProb\n",
      "  11. URLCharProb\n",
      "  12. TLDLength\n",
      "  13. NoOfSubDomain\n",
      "  14. HasObfuscation\n",
      "  15. NoOfObfuscatedChar\n",
      "  16. ObfuscationRatio\n",
      "  17. NoOfLettersInURL\n",
      "  18. LetterRatioInURL\n",
      "  19. NoOfDegitsInURL\n",
      "  20. DegitRatioInURL\n",
      "  21. NoOfEqualsInURL\n",
      "  22. NoOfQMarkInURL\n",
      "  23. NoOfAmpersandInURL\n",
      "  24. NoOfOtherSpecialCharsInURL\n",
      "  25. SpacialCharRatioInURL\n",
      "  26. IsHTTPS\n",
      "  27. LineOfCode\n",
      "  28. LargestLineLength\n",
      "  29. HasTitle\n",
      "  30. Title\n",
      "  31. DomainTitleMatchScore\n",
      "  32. URLTitleMatchScore\n",
      "  33. HasFavicon\n",
      "  34. Robots\n",
      "  35. IsResponsive\n",
      "  36. NoOfURLRedirect\n",
      "  37. NoOfSelfRedirect\n",
      "  38. HasDescription\n",
      "  39. NoOfPopup\n",
      "  40. NoOfiFrame\n",
      "  41. HasExternalFormSubmit\n",
      "  42. HasSocialNet\n",
      "  43. HasSubmitButton\n",
      "  44. HasHiddenFields\n",
      "  45. HasPasswordField\n",
      "  46. Bank\n",
      "  47. Pay\n",
      "  48. Crypto\n",
      "  49. HasCopyrightInfo\n",
      "  50. NoOfImage\n",
      "  51. NoOfCSS\n",
      "  52. NoOfJS\n",
      "  53. NoOfSelfRef\n",
      "  54. NoOfEmptyRef\n",
      "  55. NoOfExternalRef\n",
      "  56. has_no_www\n",
      "  57. num_slashes\n",
      "  58. num_hyphens\n",
      "  59. URL_Profanity_Prob\n",
      "  60. URL_NumberOf_Profanity\n",
      "  61. URLContent_Profanity_Prob\n",
      "  62. URLContent_NumberOf_Profanity\n",
      "  63. label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>URL</th>\n",
       "      <th>URLLength</th>\n",
       "      <th>Domain</th>\n",
       "      <th>DomainLength</th>\n",
       "      <th>IsDomainIP</th>\n",
       "      <th>TLD</th>\n",
       "      <th>URLSimilarityIndex</th>\n",
       "      <th>CharContinuationRate</th>\n",
       "      <th>TLDLegitimateProb</th>\n",
       "      <th>...</th>\n",
       "      <th>NoOfEmptyRef</th>\n",
       "      <th>NoOfExternalRef</th>\n",
       "      <th>has_no_www</th>\n",
       "      <th>num_slashes</th>\n",
       "      <th>num_hyphens</th>\n",
       "      <th>URL_Profanity_Prob</th>\n",
       "      <th>URL_NumberOf_Profanity</th>\n",
       "      <th>URLContent_Profanity_Prob</th>\n",
       "      <th>URLContent_NumberOf_Profanity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>521848.txt</td>\n",
       "      <td>https://www.southbankmosaics.com</td>\n",
       "      <td>32</td>\n",
       "      <td>www.southbankmosaics.com</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>com</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522907</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31372.txt</td>\n",
       "      <td>https://www.uni-mainz.de</td>\n",
       "      <td>24</td>\n",
       "      <td>www.uni-mainz.de</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>de</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.032650</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>597387.txt</td>\n",
       "      <td>https://www.voicefmradio.co.uk</td>\n",
       "      <td>30</td>\n",
       "      <td>www.voicefmradio.co.uk</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>uk</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.028555</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>554095.txt</td>\n",
       "      <td>https://www.sfnmjournal.com</td>\n",
       "      <td>27</td>\n",
       "      <td>www.sfnmjournal.com</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>com</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522907</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151578.txt</td>\n",
       "      <td>https://www.rewildingargentina.org</td>\n",
       "      <td>34</td>\n",
       "      <td>www.rewildingargentina.org</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079963</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FILENAME                                 URL  URLLength  \\\n",
       "0  521848.txt    https://www.southbankmosaics.com         32   \n",
       "1   31372.txt            https://www.uni-mainz.de         24   \n",
       "2  597387.txt      https://www.voicefmradio.co.uk         30   \n",
       "3  554095.txt         https://www.sfnmjournal.com         27   \n",
       "4  151578.txt  https://www.rewildingargentina.org         34   \n",
       "\n",
       "                       Domain  DomainLength  IsDomainIP  TLD  \\\n",
       "0    www.southbankmosaics.com            24           0  com   \n",
       "1            www.uni-mainz.de            16           0   de   \n",
       "2      www.voicefmradio.co.uk            22           0   uk   \n",
       "3         www.sfnmjournal.com            19           0  com   \n",
       "4  www.rewildingargentina.org            26           0  org   \n",
       "\n",
       "   URLSimilarityIndex  CharContinuationRate  TLDLegitimateProb  ...  \\\n",
       "0               100.0              1.000000           0.522907  ...   \n",
       "1               100.0              0.666667           0.032650  ...   \n",
       "2               100.0              0.866667           0.028555  ...   \n",
       "3               100.0              1.000000           0.522907  ...   \n",
       "4               100.0              1.000000           0.079963  ...   \n",
       "\n",
       "   NoOfEmptyRef  NoOfExternalRef  has_no_www  num_slashes  num_hyphens  \\\n",
       "0             0              124           0            2            0   \n",
       "1             0              217           0            2            1   \n",
       "2             2                5           0            2            0   \n",
       "3             1               31           0            2            0   \n",
       "4             1               85           0            2            0   \n",
       "\n",
       "   URL_Profanity_Prob  URL_NumberOf_Profanity  URLContent_Profanity_Prob  \\\n",
       "0            0.012189                       1                   0.011880   \n",
       "1            0.027988                       0                   0.019723   \n",
       "2            0.015063                       0                   0.000294   \n",
       "3            0.012189                       0                   0.000000   \n",
       "4            0.005476                       0                   0.002091   \n",
       "\n",
       "   URLContent_NumberOf_Profanity  label  \n",
       "0                              1      1  \n",
       "1                              0      1  \n",
       "2                              1      1  \n",
       "3                              0      1  \n",
       "4                             48      1  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with 63 features\n",
    "df = pd.read_csv('new_dataset/PhiUSIIL_Phishing_URL_63_Features.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Number of Rows: {len(df)}\")\n",
    "print(f\"Number of Columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumn Names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0f6b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column: label\n",
      "Target distribution:\n",
      "label\n",
      "1    134850\n",
      "0    100945\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "# Exclude non-feature columns (URL, FILENAME, etc.)\n",
    "exclude_cols = ['URL', 'FILENAME', 'Domain', 'TLD', 'Title']\n",
    "target_col = 'label'  # Adjust if your target column has different name\n",
    "\n",
    "# Find the target column\n",
    "if 'label' in df.columns:\n",
    "    target_col = 'label'\n",
    "elif 'Label' in df.columns:\n",
    "    target_col = 'Label'\n",
    "elif 'CLASS_LABEL' in df.columns:\n",
    "    target_col = 'CLASS_LABEL'\n",
    "else:\n",
    "    print(\"Target column not found! Please specify manually.\")\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "\n",
    "print(f\"Target column: {target_col}\")\n",
    "print(f\"Target distribution:\\n{df[target_col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f53e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature columns: 57\n",
      "\n",
      "Feature columns:\n",
      "  1. URLLength\n",
      "  2. DomainLength\n",
      "  3. IsDomainIP\n",
      "  4. URLSimilarityIndex\n",
      "  5. CharContinuationRate\n",
      "  6. TLDLegitimateProb\n",
      "  7. URLCharProb\n",
      "  8. TLDLength\n",
      "  9. NoOfSubDomain\n",
      "  10. HasObfuscation\n",
      "  11. NoOfObfuscatedChar\n",
      "  12. ObfuscationRatio\n",
      "  13. NoOfLettersInURL\n",
      "  14. LetterRatioInURL\n",
      "  15. NoOfDegitsInURL\n",
      "  16. DegitRatioInURL\n",
      "  17. NoOfEqualsInURL\n",
      "  18. NoOfQMarkInURL\n",
      "  19. NoOfAmpersandInURL\n",
      "  20. NoOfOtherSpecialCharsInURL\n",
      "  21. SpacialCharRatioInURL\n",
      "  22. IsHTTPS\n",
      "  23. LineOfCode\n",
      "  24. LargestLineLength\n",
      "  25. HasTitle\n",
      "  26. DomainTitleMatchScore\n",
      "  27. URLTitleMatchScore\n",
      "  28. HasFavicon\n",
      "  29. Robots\n",
      "  30. IsResponsive\n",
      "  31. NoOfURLRedirect\n",
      "  32. NoOfSelfRedirect\n",
      "  33. HasDescription\n",
      "  34. NoOfPopup\n",
      "  35. NoOfiFrame\n",
      "  36. HasExternalFormSubmit\n",
      "  37. HasSocialNet\n",
      "  38. HasSubmitButton\n",
      "  39. HasHiddenFields\n",
      "  40. HasPasswordField\n",
      "  41. Bank\n",
      "  42. Pay\n",
      "  43. Crypto\n",
      "  44. HasCopyrightInfo\n",
      "  45. NoOfImage\n",
      "  46. NoOfCSS\n",
      "  47. NoOfJS\n",
      "  48. NoOfSelfRef\n",
      "  49. NoOfEmptyRef\n",
      "  50. NoOfExternalRef\n",
      "  51. has_no_www\n",
      "  52. num_slashes\n",
      "  53. num_hyphens\n",
      "  54. URL_Profanity_Prob\n",
      "  55. URL_NumberOf_Profanity\n",
      "  56. URLContent_Profanity_Prob\n",
      "  57. URLContent_NumberOf_Profanity\n",
      "\n",
      "Feature matrix shape: (235795, 57)\n",
      "Target vector shape: (235795,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature matrix X and target vector y\n",
    "# Get only numeric columns for features\n",
    "feature_cols = [col for col in df.columns \n",
    "                if col not in exclude_cols + [target_col] \n",
    "                and df[col].dtype in ['int64', 'float64', 'int32', 'float32']]\n",
    "\n",
    "print(f\"Number of feature columns: {len(feature_cols)}\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Encode target if needed\n",
    "if y.dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    print(f\"\\nTarget encoded: {le.classes_}\")\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe99c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA SPLIT\n",
      "======================================================================\n",
      "Training set: 188636 samples\n",
      "Test set: 47159 samples\n",
      "Number of features: 57\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA SPLIT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee06340",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Feature Selection Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c515c",
   "metadata": {},
   "source": [
    "### 2.1 Boruta Feature Selection\n",
    "\n",
    "**How Boruta Works:**\n",
    "- Boruta is a wrapper algorithm that uses Random Forest to determine feature importance\n",
    "- It creates \"shadow features\" by shuffling original features randomly\n",
    "- It compares each original feature's importance against the maximum importance of shadow features\n",
    "- Features that consistently outperform shadow features are confirmed as important\n",
    "- Features that don't outperform shadow features are rejected\n",
    "\n",
    "**Why Features Are Selected:**\n",
    "- Features are selected based on their ability to distinguish between classes better than random chance\n",
    "- The algorithm uses statistical tests to ensure the selection is robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6629406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BORUTA FEATURE SELECTION\n",
      "======================================================================\n",
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t4\n",
      "Rejected: \t1\n",
      "\n",
      "Boruta completed in 1983.55 seconds\n",
      "Selected 52 features out of 57\n",
      "\n",
      "Top 10 most important features (Boruta):\n",
      "           feature  importance\n",
      "URLSimilarityIndex    0.216753\n",
      "        LineOfCode    0.154901\n",
      "   NoOfExternalRef    0.115893\n",
      "       NoOfSelfRef    0.093042\n",
      "            NoOfJS    0.056995\n",
      "    HasDescription    0.055622\n",
      "         NoOfImage    0.047761\n",
      "      HasSocialNet    0.035257\n",
      "           NoOfCSS    0.032141\n",
      "  HasCopyrightInfo    0.030206\n",
      "\n",
      "======================================================================\n",
      "BORUTA ALGORITHM EXPLANATION\n",
      "======================================================================\n",
      "\n",
      "Why these features are selected:\n",
      "\n",
      "1. URLSimilarityIndex: Measures how similar a URL is to legitimate URLs.\n",
      "   - High importance because phishing URLs often have low similarity to real sites.\n",
      "\n",
      "2. HasSocialNet/HasCopyrightInfo: Presence of social media links/copyright info.\n",
      "   - Legitimate sites usually have these; phishing sites often don't.\n",
      "\n",
      "3. IsHTTPS: Whether the site uses secure connection.\n",
      "   - Phishing sites often lack SSL certificates.\n",
      "\n",
      "4. LineOfCode/LargestLineLength: Code structure metrics.\n",
      "   - Phishing pages often have simpler or copied code patterns.\n",
      "\n",
      "5. URL structure features (NoOfSubDomain, URLLength, etc.):\n",
      "   - Phishing URLs tend to be longer, have more subdomains.\n",
      "\n",
      "Boruta confirms features by comparing them against \"shadow\" (shuffled) features.\n",
      "Only features that consistently beat random noise are selected.\n",
      "\n",
      "\n",
      "All selected features:\n",
      "  1. URLLength\n",
      "  2. DomainLength\n",
      "  3. URLSimilarityIndex\n",
      "  4. CharContinuationRate\n",
      "  5. TLDLegitimateProb\n",
      "  6. URLCharProb\n",
      "  7. TLDLength\n",
      "  8. NoOfSubDomain\n",
      "  9. NoOfObfuscatedChar\n",
      "  10. NoOfLettersInURL\n",
      "  11. LetterRatioInURL\n",
      "  12. NoOfDegitsInURL\n",
      "  13. DegitRatioInURL\n",
      "  14. NoOfEqualsInURL\n",
      "  15. NoOfQMarkInURL\n",
      "  16. NoOfAmpersandInURL\n",
      "  17. NoOfOtherSpecialCharsInURL\n",
      "  18. SpacialCharRatioInURL\n",
      "  19. IsHTTPS\n",
      "  20. LineOfCode\n",
      "  21. LargestLineLength\n",
      "  22. HasTitle\n",
      "  23. DomainTitleMatchScore\n",
      "  24. URLTitleMatchScore\n",
      "  25. HasFavicon\n",
      "  26. Robots\n",
      "  27. IsResponsive\n",
      "  28. NoOfURLRedirect\n",
      "  29. HasDescription\n",
      "  30. NoOfPopup\n",
      "  31. NoOfiFrame\n",
      "  32. HasExternalFormSubmit\n",
      "  33. HasSocialNet\n",
      "  34. HasSubmitButton\n",
      "  35. HasHiddenFields\n",
      "  36. HasPasswordField\n",
      "  37. Bank\n",
      "  38. Pay\n",
      "  39. HasCopyrightInfo\n",
      "  40. NoOfImage\n",
      "  41. NoOfCSS\n",
      "  42. NoOfJS\n",
      "  43. NoOfSelfRef\n",
      "  44. NoOfEmptyRef\n",
      "  45. NoOfExternalRef\n",
      "  46. has_no_www\n",
      "  47. num_slashes\n",
      "  48. num_hyphens\n",
      "  49. URL_Profanity_Prob\n",
      "  50. URL_NumberOf_Profanity\n",
      "  51. URLContent_Profanity_Prob\n",
      "  52. URLContent_NumberOf_Profanity\n"
     ]
    }
   ],
   "source": [
    "# Boruta Feature Selection\n",
    "print(\"=\" * 70)\n",
    "print(\"BORUTA FEATURE SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize Random Forest for Boruta\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5, random_state=42)\n",
    "\n",
    "# Initialize Boruta\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42, max_iter=100)\n",
    "\n",
    "# Fit Boruta\n",
    "start_time = time.time()\n",
    "boruta_selector.fit(X_train.values, y_train)\n",
    "boruta_time = time.time() - start_time\n",
    "\n",
    "# Get selected features\n",
    "boruta_features = X_train.columns[boruta_selector.support_].tolist()\n",
    "\n",
    "# Get feature rankings from Boruta (lower rank = more important)\n",
    "# ranking_ gives the rank where 1 is the most important\n",
    "boruta_ranking = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'rank': boruta_selector.ranking_,\n",
    "    'selected': boruta_selector.support_\n",
    "})\n",
    "\n",
    "# To get importance scores, we'll use the Random Forest that Boruta trained\n",
    "# But boruta doesn't expose this directly, so we'll train RF on all features\n",
    "rf_for_importance = RandomForestClassifier(n_jobs=-1, class_weight='balanced', \n",
    "                                            max_depth=5, random_state=42, n_estimators=100)\n",
    "rf_for_importance.fit(X_train, y_train)\n",
    "\n",
    "# Create importance scores\n",
    "boruta_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_for_importance.feature_importances_,\n",
    "    'boruta_rank': boruta_selector.ranking_,\n",
    "    'selected': boruta_selector.support_\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "boruta_importance_df = boruta_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nBoruta completed in {boruta_time:.2f} seconds\")\n",
    "print(f\"Selected {len(boruta_features)} features out of {X_train.shape[1]}\")\n",
    "\n",
    "# Display Top 10 most important features\n",
    "print(f\"\\nTop 10 most important features (Boruta):\")\n",
    "print(boruta_importance_df.head(10)[['feature', 'importance']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"BORUTA ALGORITHM EXPLANATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Why these features are selected:\n",
    "\n",
    "1. URLSimilarityIndex: Measures how similar a URL is to legitimate URLs.\n",
    "   - High importance because phishing URLs often have low similarity to real sites.\n",
    "\n",
    "2. HasSocialNet/HasCopyrightInfo: Presence of social media links/copyright info.\n",
    "   - Legitimate sites usually have these; phishing sites often don't.\n",
    "\n",
    "3. IsHTTPS: Whether the site uses secure connection.\n",
    "   - Phishing sites often lack SSL certificates.\n",
    "\n",
    "4. LineOfCode/LargestLineLength: Code structure metrics.\n",
    "   - Phishing pages often have simpler or copied code patterns.\n",
    "\n",
    "5. URL structure features (NoOfSubDomain, URLLength, etc.):\n",
    "   - Phishing URLs tend to be longer, have more subdomains.\n",
    "\n",
    "Boruta confirms features by comparing them against \"shadow\" (shuffled) features.\n",
    "Only features that consistently beat random noise are selected.\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nAll selected features:\")\n",
    "for i, f in enumerate(boruta_features, 1):\n",
    "    print(f\"  {i}. {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bbdd3c",
   "metadata": {},
   "source": [
    "### 2.2 RFE (Recursive Feature Elimination)\n",
    "\n",
    "**How RFE Works:**\n",
    "- RFE starts with all features and recursively removes the least important ones\n",
    "- At each iteration, it trains a model and ranks features by importance\n",
    "- The least important feature(s) are removed\n",
    "- This process continues until the desired number of features is reached\n",
    "\n",
    "**Why Features Are Selected:**\n",
    "- Features that survive to the end are consistently important across multiple model iterations\n",
    "- The ranking reflects the order in which features were eliminated (later = more important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b4953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RFE (RECURSIVE FEATURE ELIMINATION)\n",
      "======================================================================\n",
      "\n",
      "RFE completed in 131.33 seconds\n",
      "Selected 20 features out of 57\n",
      "\n",
      "Top 10 most important features (RFE with LightGBM):\n",
      "              feature  importance\n",
      "           LineOfCode         499\n",
      "    LargestLineLength         471\n",
      "      NoOfExternalRef         277\n",
      "          URLCharProb         269\n",
      "     LetterRatioInURL         242\n",
      "SpacialCharRatioInURL         180\n",
      "              IsHTTPS         161\n",
      "            URLLength         128\n",
      "               NoOfJS         104\n",
      "   URLSimilarityIndex         102\n",
      "\n",
      "======================================================================\n",
      "RFE ALGORITHM EXPLANATION\n",
      "======================================================================\n",
      "\n",
      "Why these features are selected:\n",
      "\n",
      "RFE uses LightGBM's built-in feature importance (gain-based) to rank features.\n",
      "Features are eliminated one by one based on their contribution to model accuracy.\n",
      "\n",
      "1. URLSimilarityIndex: Highest gain contribution - strongly separates phishing/legitimate.\n",
      "\n",
      "2. LineOfCode/LargestLineLength: Page complexity metrics have high predictive power.\n",
      "   - Phishing pages often have minimal/copied code.\n",
      "\n",
      "3. NoOfExternalRef: Number of external references indicates site legitimacy.\n",
      "   - Legitimate sites reference many external resources.\n",
      "\n",
      "4. URLCharProb: Probability distribution of characters in URL.\n",
      "   - Phishing URLs often contain unusual character patterns.\n",
      "\n",
      "5. IsHTTPS: Security indicator that can distinguish many phishing attempts.\n",
      "\n",
      "RFE is robust because features that remain important throughout recursive\n",
      "elimination are truly essential for classification, not just noise.\n",
      "\n",
      "\n",
      "Selected features:\n",
      "  1. URLLength\n",
      "  2. URLSimilarityIndex\n",
      "  3. CharContinuationRate\n",
      "  4. TLDLegitimateProb\n",
      "  5. URLCharProb\n",
      "  6. NoOfSubDomain\n",
      "  7. NoOfLettersInURL\n",
      "  8. LetterRatioInURL\n",
      "  9. SpacialCharRatioInURL\n",
      "  10. IsHTTPS\n",
      "  11. LineOfCode\n",
      "  12. LargestLineLength\n",
      "  13. HasDescription\n",
      "  14. NoOfImage\n",
      "  15. NoOfCSS\n",
      "  16. NoOfJS\n",
      "  17. NoOfSelfRef\n",
      "  18. NoOfEmptyRef\n",
      "  19. NoOfExternalRef\n",
      "  20. URL_Profanity_Prob\n"
     ]
    }
   ],
   "source": [
    "# RFE Feature Selection\n",
    "print(\"=\" * 70)\n",
    "print(\"RFE (RECURSIVE FEATURE ELIMINATION)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use LightGBM as base estimator for RFE\n",
    "lgbm_estimator = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "\n",
    "# Select top 20 features (adjust as needed)\n",
    "n_features_to_select = 20\n",
    "rfe_selector = RFE(estimator=lgbm_estimator, n_features_to_select=n_features_to_select, step=1)\n",
    "\n",
    "start_time = time.time()\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "rfe_time = time.time() - start_time\n",
    "\n",
    "# Get selected features\n",
    "rfe_features = X_train.columns[rfe_selector.support_].tolist()\n",
    "\n",
    "# Get feature rankings (lower = better, 1 = selected)\n",
    "rfe_ranking_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'rfe_rank': rfe_selector.ranking_,\n",
    "    'selected': rfe_selector.support_\n",
    "})\n",
    "\n",
    "# Get feature importances from the fitted estimator\n",
    "# Also train LightGBM to get importance scores for ranking\n",
    "lgbm_for_importance = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "lgbm_for_importance.fit(X_train, y_train)\n",
    "\n",
    "rfe_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': lgbm_for_importance.feature_importances_,\n",
    "    'rfe_rank': rfe_selector.ranking_,\n",
    "    'selected': rfe_selector.support_\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "rfe_importance_df = rfe_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nRFE completed in {rfe_time:.2f} seconds\")\n",
    "print(f\"Selected {len(rfe_features)} features out of {X_train.shape[1]}\")\n",
    "\n",
    "# Display Top 10 most important features\n",
    "print(f\"\\nTop 10 most important features (RFE with LightGBM):\")\n",
    "print(rfe_importance_df.head(10)[['feature', 'importance']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"RFE ALGORITHM EXPLANATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Why these features are selected:\n",
    "\n",
    "RFE uses LightGBM's built-in feature importance (gain-based) to rank features.\n",
    "Features are eliminated one by one based on their contribution to model accuracy.\n",
    "\n",
    "1. URLSimilarityIndex: Highest gain contribution - strongly separates phishing/legitimate.\n",
    "   \n",
    "2. LineOfCode/LargestLineLength: Page complexity metrics have high predictive power.\n",
    "   - Phishing pages often have minimal/copied code.\n",
    "\n",
    "3. NoOfExternalRef: Number of external references indicates site legitimacy.\n",
    "   - Legitimate sites reference many external resources.\n",
    "\n",
    "4. URLCharProb: Probability distribution of characters in URL.\n",
    "   - Phishing URLs often contain unusual character patterns.\n",
    "\n",
    "5. IsHTTPS: Security indicator that can distinguish many phishing attempts.\n",
    "\n",
    "RFE is robust because features that remain important throughout recursive\n",
    "elimination are truly essential for classification, not just noise.\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nSelected features:\")\n",
    "for i, f in enumerate(rfe_features, 1):\n",
    "    print(f\"  {i}. {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4c408",
   "metadata": {},
   "source": [
    "### 2.3 Correlation-based Feature Selection\n",
    "\n",
    "**How Correlation-based Selection Works:**\n",
    "- Calculates Pearson correlation coefficient between each feature and the target\n",
    "- Features with high absolute correlation with target are selected\n",
    "- Also removes features that are highly correlated with each other (multicollinearity)\n",
    "\n",
    "**Why Features Are Selected:**\n",
    "- High correlation with target = strong linear relationship with outcome\n",
    "- Removing redundant features reduces noise and computational cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1b3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CORRELATION-BASED FEATURE SELECTION\n",
      "======================================================================\n",
      "\n",
      "Correlation-based selection completed in 1.65 seconds\n",
      "Selected 39 features out of 57\n",
      "\n",
      "Top 10 correlated features with target:\n",
      "              feature  correlation\n",
      "   URLSimilarityIndex     0.860443\n",
      "         HasSocialNet     0.783682\n",
      "     HasCopyrightInfo     0.742820\n",
      "       HasDescription     0.690587\n",
      "           has_no_www     0.668396\n",
      "              IsHTTPS     0.612900\n",
      "DomainTitleMatchScore     0.583463\n",
      "      HasSubmitButton     0.578994\n",
      "         IsResponsive     0.548483\n",
      "   URLTitleMatchScore     0.538363\n",
      "\n",
      "======================================================================\n",
      "CORRELATION-BASED ALGORITHM EXPLANATION\n",
      "======================================================================\n",
      "\n",
      "Why these features are selected:\n",
      "\n",
      "1. URLSimilarityIndex (0.86): Highest correlation - legitimate URLs share patterns.\n",
      "   - Phishing URLs typically deviate from these patterns significantly.\n",
      "\n",
      "2. HasSocialNet (0.78): Social media presence is a legitimacy indicator.\n",
      "   - Most legitimate sites have social media integration.\n",
      "\n",
      "3. HasCopyrightInfo (0.74): Copyright notices indicate professional websites.\n",
      "   - Phishing sites rarely include proper legal information.\n",
      "\n",
      "4. HasDescription (0.69): Meta descriptions indicate proper SEO practices.\n",
      "   - Legitimate sites usually have proper metadata.\n",
      "\n",
      "5. has_no_www (0.67): URL structure indicator.\n",
      "   - Unusual URL patterns often indicate phishing.\n",
      "\n",
      "6. IsHTTPS (0.61): Security certificate presence.\n",
      "   - Legitimate sites increasingly use HTTPS; phishing sites less so.\n",
      "\n",
      "Note: Correlation measures LINEAR relationship only. Some important features\n",
      "might have non-linear relationships not captured by this method.\n",
      "\n",
      "\n",
      "Selected features:\n",
      "  1. URLSimilarityIndex\n",
      "  2. HasSocialNet\n",
      "  3. HasCopyrightInfo\n",
      "  4. HasDescription\n",
      "  5. has_no_www\n",
      "  6. IsHTTPS\n",
      "  7. DomainTitleMatchScore\n",
      "  8. HasSubmitButton\n",
      "  9. IsResponsive\n",
      "  10. SpacialCharRatioInURL\n",
      "  11. HasHiddenFields\n",
      "  12. HasFavicon\n",
      "  13. num_slashes\n",
      "  14. URLCharProb\n",
      "  15. CharContinuationRate\n",
      "  16. HasTitle\n",
      "  17. DegitRatioInURL\n",
      "  18. Robots\n",
      "  19. LetterRatioInURL\n",
      "  20. Pay\n",
      "  21. NoOfSelfRef\n",
      "  22. NoOfJS\n",
      "  23. NoOfOtherSpecialCharsInURL\n",
      "  24. NoOfExternalRef\n",
      "  25. DomainLength\n",
      "  26. NoOfImage\n",
      "  27. NoOfLettersInURL\n",
      "  28. LineOfCode\n",
      "  29. URLLength\n",
      "  30. NoOfiFrame\n",
      "  31. num_hyphens\n",
      "  32. Bank\n",
      "  33. NoOfQMarkInURL\n",
      "  34. NoOfDegitsInURL\n",
      "  35. HasExternalFormSubmit\n",
      "  36. URL_NumberOf_Profanity\n",
      "  37. URLContent_Profanity_Prob\n",
      "  38. HasPasswordField\n",
      "  39. NoOfEmptyRef\n"
     ]
    }
   ],
   "source": [
    "# Correlation-based Feature Selection\n",
    "print(\"=\" * 70)\n",
    "print(\"CORRELATION-BASED FEATURE SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Calculate correlation with target\n",
    "correlations = pd.DataFrame()\n",
    "correlations['feature'] = feature_cols\n",
    "correlations['correlation'] = [abs(X_train[col].corr(pd.Series(y_train))) for col in feature_cols]\n",
    "correlations = correlations.sort_values('correlation', ascending=False)\n",
    "\n",
    "# Select features with correlation > threshold or top N features\n",
    "correlation_threshold = 0.1\n",
    "corr_features = correlations[correlations['correlation'] >= correlation_threshold]['feature'].tolist()\n",
    "\n",
    "# Also remove highly correlated features among themselves\n",
    "corr_matrix = X_train[corr_features].corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
    "corr_features_final = [f for f in corr_features if f not in to_drop]\n",
    "\n",
    "corr_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nCorrelation-based selection completed in {corr_time:.2f} seconds\")\n",
    "print(f\"Selected {len(corr_features_final)} features out of {X_train.shape[1]}\")\n",
    "\n",
    "# Display Top 10 correlated features\n",
    "print(f\"\\nTop 10 correlated features with target:\")\n",
    "print(correlations.head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELATION-BASED ALGORITHM EXPLANATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Why these features are selected:\n",
    "\n",
    "1. URLSimilarityIndex (0.86): Highest correlation - legitimate URLs share patterns.\n",
    "   - Phishing URLs typically deviate from these patterns significantly.\n",
    "\n",
    "2. HasSocialNet (0.78): Social media presence is a legitimacy indicator.\n",
    "   - Most legitimate sites have social media integration.\n",
    "\n",
    "3. HasCopyrightInfo (0.74): Copyright notices indicate professional websites.\n",
    "   - Phishing sites rarely include proper legal information.\n",
    "\n",
    "4. HasDescription (0.69): Meta descriptions indicate proper SEO practices.\n",
    "   - Legitimate sites usually have proper metadata.\n",
    "\n",
    "5. has_no_www (0.67): URL structure indicator.\n",
    "   - Unusual URL patterns often indicate phishing.\n",
    "\n",
    "6. IsHTTPS (0.61): Security certificate presence.\n",
    "   - Legitimate sites increasingly use HTTPS; phishing sites less so.\n",
    "\n",
    "Note: Correlation measures LINEAR relationship only. Some important features\n",
    "might have non-linear relationships not captured by this method.\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nSelected features:\")\n",
    "for i, f in enumerate(corr_features_final, 1):\n",
    "    print(f\"  {i}. {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c05e2d",
   "metadata": {},
   "source": [
    "### 2.4 ContrastFS (Contrastive Feature Selection)\n",
    "\n",
    "**How ContrastFS Works:**\n",
    "- Measures each feature's ability to separate different classes\n",
    "- Calculates **intra-class distance** (samples within same class should be similar)\n",
    "- Calculates **inter-class distance** (samples from different classes should be different)\n",
    "- Computes **Contrast Score** = inter-class distance / intra-class distance\n",
    "- Higher contrast score = better discriminative power\n",
    "\n",
    "**Why Features Are Selected:**\n",
    "- Features that maximize separation between classes while keeping similar classes close\n",
    "- Based on contrastive learning principles: 'push apart' different classes, 'pull together' same class\n",
    "- More robust than single-model importance as it directly measures class separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25576ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONTRASTFS (CONTRASTIVE FEATURE SELECTION)\n",
      "======================================================================\n",
      "\n",
      "ContrastFS completed in 0.06 seconds\n",
      "Selected 20 features out of 57\n",
      "\n",
      "Top 10 features by ContrastFS score:\n",
      "              feature  contrast_score  normalized_score\n",
      "   URLSimilarityIndex       11.191154          1.000000\n",
      "         HasSocialNet        6.384796          0.570522\n",
      "     HasCopyrightInfo        5.110844          0.456686\n",
      "       HasDescription        3.708168          0.331348\n",
      "           has_no_www        3.396335          0.303484\n",
      "              IsHTTPS        2.524480          0.225578\n",
      "      HasSubmitButton        2.098836          0.187544\n",
      "DomainTitleMatchScore        2.095428          0.187240\n",
      "         IsResponsive        1.843700          0.164746\n",
      "   URLTitleMatchScore        1.630732          0.145716\n",
      "\n",
      "======================================================================\n",
      "CONTRASTFS ALGORITHM EXPLANATION\n",
      "======================================================================\n",
      "\n",
      "Why these features are selected:\n",
      "\n",
      "ContrastFS uses contrastive learning principles to evaluate features:\n",
      "\n",
      "1. HIGH CONTRAST SCORE features can effectively separate classes:\n",
      "   - Large distance between class means (inter-class)\n",
      "   - Small variance within each class (intra-class)\n",
      "\n",
      "2. The algorithm calculates for each feature:\n",
      "   - Intra-class variance: How spread out samples are within the same class\n",
      "   - Inter-class distance: How far apart the class centers are\n",
      "   - Contrast Score = Inter-class Distance / Intra-class Variance\n",
      "\n",
      "3. Interpretation:\n",
      "   - High score = Feature creates clear separation between phishing & legitimate\n",
      "   - Low score = Feature values overlap significantly between classes\n",
      "\n",
      "4. Advantages over tree-based importance:\n",
      "   - Model-agnostic: Does not depend on any specific classifier\n",
      "   - Direct measurement: Measures actual class separability\n",
      "   - No training bias: Pure statistical measure of discriminative power\n",
      "\n",
      "5. Features with highest contrast scores are most effective at:\n",
      "   - Distinguishing phishing URLs from legitimate ones\n",
      "   - Creating decision boundaries in the feature space\n",
      "\n",
      "\n",
      "Selected features (Top 20 by ContrastFS):\n",
      "  1. URLSimilarityIndex\n",
      "  2. HasSocialNet\n",
      "  3. HasCopyrightInfo\n",
      "  4. HasDescription\n",
      "  5. has_no_www\n",
      "  6. IsHTTPS\n",
      "  7. HasSubmitButton\n",
      "  8. DomainTitleMatchScore\n",
      "  9. IsResponsive\n",
      "  10. URLTitleMatchScore\n",
      "  11. SpacialCharRatioInURL\n",
      "  12. HasHiddenFields\n",
      "  13. num_slashes\n",
      "  14. HasFavicon\n",
      "  15. URLCharProb\n",
      "  16. CharContinuationRate\n",
      "  17. HasTitle\n",
      "  18. DegitRatioInURL\n",
      "  19. NoOfCSS\n",
      "  20. Robots\n"
     ]
    }
   ],
   "source": [
    "# ContrastFS (Contrastive Feature Selection)\n",
    "print(\"=\" * 70)\n",
    "print(\"CONTRASTFS (CONTRASTIVE FEATURE SELECTION)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def contrastfs_score(X, y, n_samples=5000):\n",
    "    \"\"\"\n",
    "    Calculate ContrastFS scores for each feature.\n",
    "    \n",
    "    ContrastFS measures feature importance based on contrastive learning principles:\n",
    "    - Good features should maximize inter-class distance (different classes far apart)\n",
    "    - Good features should minimize intra-class distance (same class samples close)\n",
    "    - Contrast Score = inter-class distance / intra-class distance\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame - Feature matrix\n",
    "    y : array-like - Target labels\n",
    "    n_samples : int - Number of samples to use (for efficiency)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with feature names and their contrast scores\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Sample data for efficiency (large datasets)\n",
    "    if len(X) > n_samples:\n",
    "        np.random.seed(42)\n",
    "        indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "        X_sample = X.iloc[indices].values\n",
    "        y_sample = np.array(y)[indices] if hasattr(y, '__iter__') else y.iloc[indices].values\n",
    "    else:\n",
    "        X_sample = X.values\n",
    "        y_sample = np.array(y)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_sample)\n",
    "    \n",
    "    # Get unique classes\n",
    "    classes = np.unique(y_sample)\n",
    "    n_features = X_scaled.shape[1]\n",
    "    \n",
    "    contrast_scores = []\n",
    "    \n",
    "    for feat_idx in range(n_features):\n",
    "        feature_values = X_scaled[:, feat_idx]\n",
    "        \n",
    "        # Calculate intra-class variance (samples within same class)\n",
    "        intra_class_var = 0\n",
    "        for c in classes:\n",
    "            class_mask = (y_sample == c)\n",
    "            class_values = feature_values[class_mask]\n",
    "            if len(class_values) > 1:\n",
    "                intra_class_var += np.var(class_values) * len(class_values)\n",
    "        intra_class_var /= len(y_sample)\n",
    "        \n",
    "        # Calculate inter-class distance (distance between class means)\n",
    "        class_means = []\n",
    "        class_sizes = []\n",
    "        for c in classes:\n",
    "            class_mask = (y_sample == c)\n",
    "            class_values = feature_values[class_mask]\n",
    "            class_means.append(np.mean(class_values))\n",
    "            class_sizes.append(len(class_values))\n",
    "        \n",
    "        # Weighted inter-class distance\n",
    "        inter_class_dist = 0\n",
    "        total_pairs = 0\n",
    "        for i in range(len(classes)):\n",
    "            for j in range(i + 1, len(classes)):\n",
    "                weight = class_sizes[i] * class_sizes[j]\n",
    "                inter_class_dist += weight * (class_means[i] - class_means[j]) ** 2\n",
    "                total_pairs += weight\n",
    "        \n",
    "        if total_pairs > 0:\n",
    "            inter_class_dist /= total_pairs\n",
    "        \n",
    "        # Contrast Score = inter-class distance / (intra-class variance + epsilon)\n",
    "        epsilon = 1e-10  # Avoid division by zero\n",
    "        contrast_score = inter_class_dist / (intra_class_var + epsilon)\n",
    "        contrast_scores.append(contrast_score)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'contrast_score': contrast_scores\n",
    "    })\n",
    "    results_df = results_df.sort_values('contrast_score', ascending=False)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Apply ContrastFS\n",
    "contrastfs_df = contrastfs_score(X_train, y_train, n_samples=10000)\n",
    "\n",
    "# Normalize scores to [0, 1]\n",
    "contrastfs_df['normalized_score'] = contrastfs_df['contrast_score'] / contrastfs_df['contrast_score'].max()\n",
    "\n",
    "# Select features with contrast score above threshold (top percentile or fixed threshold)\n",
    "# Method 1: Top N features\n",
    "n_top_features = 20\n",
    "contrastfs_features = contrastfs_df.head(n_top_features)['feature'].tolist()\n",
    "\n",
    "# Method 2: Threshold-based (features with score > 10% of max)\n",
    "# threshold = 0.1\n",
    "# contrastfs_features = contrastfs_df[contrastfs_df['normalized_score'] >= threshold]['feature'].tolist()\n",
    "\n",
    "contrastfs_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nContrastFS completed in {contrastfs_time:.2f} seconds\")\n",
    "print(f\"Selected {len(contrastfs_features)} features out of {X_train.shape[1]}\")\n",
    "\n",
    "# Display Top 10 features by contrast score\n",
    "print(f\"\\nTop 10 features by ContrastFS score:\")\n",
    "print(contrastfs_df.head(10)[['feature', 'contrast_score', 'normalized_score']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"CONTRASTFS ALGORITHM EXPLANATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Why these features are selected:\n",
    "\n",
    "ContrastFS uses contrastive learning principles to evaluate features:\n",
    "\n",
    "1. HIGH CONTRAST SCORE features can effectively separate classes:\n",
    "   - Large distance between class means (inter-class)\n",
    "   - Small variance within each class (intra-class)\n",
    "\n",
    "2. The algorithm calculates for each feature:\n",
    "   - Intra-class variance: How spread out samples are within the same class\n",
    "   - Inter-class distance: How far apart the class centers are\n",
    "   - Contrast Score = Inter-class Distance / Intra-class Variance\n",
    "\n",
    "3. Interpretation:\n",
    "   - High score = Feature creates clear separation between phishing & legitimate\n",
    "   - Low score = Feature values overlap significantly between classes\n",
    "\n",
    "4. Advantages over tree-based importance:\n",
    "   - Model-agnostic: Does not depend on any specific classifier\n",
    "   - Direct measurement: Measures actual class separability\n",
    "   - No training bias: Pure statistical measure of discriminative power\n",
    "\n",
    "5. Features with highest contrast scores are most effective at:\n",
    "   - Distinguishing phishing URLs from legitimate ones\n",
    "   - Creating decision boundaries in the feature space\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nSelected features (Top {n_top_features} by ContrastFS):\")\n",
    "for i, f in enumerate(contrastfs_features, 1):\n",
    "    print(f\"  {i}. {f}\")\n",
    "\n",
    "# Store for later comparison (rename to match expected variable name)\n",
    "contrast_features = contrastfs_features  # Keep compatibility with rest of notebook\n",
    "contrast_time = contrastfs_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda10967",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Compare Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dce821b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE SELECTION SUMMARY\n",
      "======================================================================\n",
      "           Method  Num Features  Selection Time (s)\n",
      "     All Features            57                0.00\n",
      "           Boruta            52             1983.55\n",
      "              RFE            20              131.33\n",
      "Correlation-based            39                1.65\n",
      "       ContrastFS            20                0.06\n",
      "\n",
      "Common features across all methods: 6\n",
      "  - URLSimilarityIndex\n",
      "  - HasDescription\n",
      "  - URLCharProb\n",
      "  - CharContinuationRate\n",
      "  - SpacialCharRatioInURL\n",
      "  - IsHTTPS\n"
     ]
    }
   ],
   "source": [
    "# Summary of all feature selection methods\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE SELECTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "selection_summary = {\n",
    "    'Method': ['All Features', 'Boruta', 'RFE', 'Correlation-based', 'ContrastFS'],\n",
    "    'Num Features': [\n",
    "        len(feature_cols),\n",
    "        len(boruta_features),\n",
    "        len(rfe_features),\n",
    "        len(corr_features_final),\n",
    "        len(contrast_features)\n",
    "    ],\n",
    "    'Selection Time (s)': [\n",
    "        0,\n",
    "        round(boruta_time, 2),\n",
    "        round(rfe_time, 2),\n",
    "        round(corr_time, 2),\n",
    "        round(contrast_time, 2)\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(selection_summary)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Find common features across all methods\n",
    "common_features = set(boruta_features) & set(rfe_features) & set(corr_features_final) & set(contrast_features)\n",
    "print(f\"\\nCommon features across all methods: {len(common_features)}\")\n",
    "for f in common_features:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "top10_comparison",
   "metadata": {},
   "source": [
    "### Top 10 Features Comparison Across All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "top10_table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "TOP 10 FEATURES COMPARISON ACROSS ALL METHODS\n",
      "====================================================================================================\n",
      " Rank Boruta (RF Importance)        RFE (LightGBM)           Correlation            ContrastFS\n",
      "    1     URLSimilarityIndex            LineOfCode    URLSimilarityIndex    URLSimilarityIndex\n",
      "    2             LineOfCode     LargestLineLength          HasSocialNet          HasSocialNet\n",
      "    3        NoOfExternalRef       NoOfExternalRef      HasCopyrightInfo      HasCopyrightInfo\n",
      "    4            NoOfSelfRef           URLCharProb        HasDescription        HasDescription\n",
      "    5                 NoOfJS      LetterRatioInURL            has_no_www            has_no_www\n",
      "    6         HasDescription SpacialCharRatioInURL               IsHTTPS               IsHTTPS\n",
      "    7              NoOfImage               IsHTTPS DomainTitleMatchScore       HasSubmitButton\n",
      "    8           HasSocialNet             URLLength       HasSubmitButton DomainTitleMatchScore\n",
      "    9                NoOfCSS                NoOfJS          IsResponsive          IsResponsive\n",
      "   10       HasCopyrightInfo    URLSimilarityIndex    URLTitleMatchScore    URLTitleMatchScore\n",
      "\n",
      "====================================================================================================\n",
      "TOP 10 FEATURES WITH SCORES\n",
      "====================================================================================================\n",
      " Rank     Boruta Feature  Score           RFE Feature  Score           Corr Feature  Score      ContrastFS Feature  Score   \n",
      "    1 URLSimilarityIndex 0.2168            LineOfCode     499    URLSimilarityIndex   0.8604    URLSimilarityIndex    1.0000\n",
      "    2         LineOfCode 0.1549     LargestLineLength     471          HasSocialNet   0.7837          HasSocialNet    0.5705\n",
      "    3    NoOfExternalRef 0.1159       NoOfExternalRef     277      HasCopyrightInfo   0.7428      HasCopyrightInfo    0.4567\n",
      "    4        NoOfSelfRef 0.0930           URLCharProb     269        HasDescription   0.6906        HasDescription    0.3313\n",
      "    5             NoOfJS 0.0570      LetterRatioInURL     242            has_no_www   0.6684            has_no_www    0.3035\n",
      "    6     HasDescription 0.0556 SpacialCharRatioInURL     180               IsHTTPS   0.6129               IsHTTPS    0.2256\n",
      "    7          NoOfImage 0.0478               IsHTTPS     161 DomainTitleMatchScore   0.5835       HasSubmitButton    0.1875\n",
      "    8       HasSocialNet 0.0353             URLLength     128       HasSubmitButton   0.5790 DomainTitleMatchScore    0.1872\n",
      "    9            NoOfCSS 0.0321                NoOfJS     104          IsResponsive   0.5485          IsResponsive    0.1647\n",
      "   10   HasCopyrightInfo 0.0302    URLSimilarityIndex     102    URLTitleMatchScore   0.5384    URLTitleMatchScore    0.1457\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive Top 10 comparison table\n",
    "print(\"=\" * 100)\n",
    "print(\"TOP 10 FEATURES COMPARISON ACROSS ALL METHODS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Get Top 10 from each method\n",
    "top10_comparison = pd.DataFrame({\n",
    "    'Rank': range(1, 11),\n",
    "    'Boruta (RF Importance)': boruta_importance_df.head(10)['feature'].values,\n",
    "    'RFE (LightGBM)': rfe_importance_df.head(10)['feature'].values,\n",
    "    'Correlation': correlations.head(10)['feature'].values,\n",
    "    'ContrastFS': contrastfs_df.head(10)['feature'].values\n",
    "})\n",
    "\n",
    "print(top10_comparison.to_string(index=False))\n",
    "\n",
    "# Create importance scores table\n",
    "print(f\"\\n\" + \"=\"*100)\n",
    "print(\"TOP 10 FEATURES WITH SCORES\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "top10_scores = pd.DataFrame({\n",
    "    'Rank': range(1, 11),\n",
    "    'Boruta Feature': boruta_importance_df.head(10)['feature'].values,\n",
    "    'Score': boruta_importance_df.head(10)['importance'].round(4).values,\n",
    "    'RFE Feature': rfe_importance_df.head(10)['feature'].values,\n",
    "    'Score ': rfe_importance_df.head(10)['importance'].round(4).values,\n",
    "    'Corr Feature': correlations.head(10)['feature'].values,\n",
    "    'Score  ': correlations.head(10)['correlation'].round(4).values,\n",
    "    'ContrastFS Feature': contrastfs_df.head(10)['feature'].values,\n",
    "    'Score   ': contrastfs_df.head(10)['normalized_score'].round(4).values\n",
    "})\n",
    "\n",
    "print(top10_scores.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a496d",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5268d459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Train a model and return evaluation metrics.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all metrics\n",
    "    \"\"\"\n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': round(float(accuracy), 4),\n",
    "        'Precision': round(float(precision), 4),\n",
    "        'Recall': round(float(recall), 4),\n",
    "        'F1-Score': round(float(f1), 4),\n",
    "        'MCC': round(float(mcc), 4),\n",
    "        'Training Time (s)': round(float(training_time), 4)\n",
    "    }\n",
    "\n",
    "print(\"Evaluation function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09db8e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING MODELS WITH DIFFERENT FEATURE SETS\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature sets for evaluation\n",
    "feature_sets = {\n",
    "    'All Features': feature_cols,\n",
    "    'Boruta': boruta_features,\n",
    "    'RFE': rfe_features,\n",
    "    'Correlation': corr_features_final,\n",
    "    'ContrastFS': contrastfs_features,\n",
    "}\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING MODELS WITH DIFFERENT FEATURE SETS\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d5f139e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Feature Set: All Features (57 features)\n",
      "======================================================================\n",
      "\n",
      "Training LightGBM...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 27.0539s\n",
      "Training XGBoost...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 4.9349s\n",
      "Training CatBoost...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 10.1252s\n",
      "\n",
      "======================================================================\n",
      "Feature Set: Boruta (52 features)\n",
      "======================================================================\n",
      "\n",
      "Training LightGBM...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 3.8738s\n",
      "Training XGBoost...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 3.053s\n",
      "Training CatBoost...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 15.3915s\n",
      "\n",
      "======================================================================\n",
      "Feature Set: RFE (20 features)\n",
      "======================================================================\n",
      "\n",
      "Training LightGBM...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 32.988s\n",
      "Training XGBoost...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 2.9907s\n",
      "Training CatBoost...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 10.3145s\n",
      "\n",
      "======================================================================\n",
      "Feature Set: Correlation (39 features)\n",
      "======================================================================\n",
      "\n",
      "Training LightGBM...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 3.1376s\n",
      "Training XGBoost...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 17.9066s\n",
      "Training CatBoost...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 19.4922s\n",
      "\n",
      "======================================================================\n",
      "Feature Set: ContrastFS (20 features)\n",
      "======================================================================\n",
      "\n",
      "Training LightGBM...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 11.8563s\n",
      "Training XGBoost...\n",
      "  Accuracy: 1.0, F1: 1.0, Time: 2.5773s\n",
      "Training CatBoost...\n",
      "  Accuracy: 0.9999, F1: 0.9999, Time: 7.5732s\n",
      "\n",
      "======================================================================\n",
      "ALL TRAINING COMPLETED!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Function to clean feature names for LightGBM compatibility\n",
    "import re\n",
    "def clean_feature_names(df):\n",
    "    clean_cols = {col: re.sub(r'[^a-zA-Z0-9_]', '_', str(col)) for col in df.columns}\n",
    "    return df.rename(columns=clean_cols)\n",
    "\n",
    "# Train and evaluate all models with all feature sets\n",
    "for fs_name, features in feature_sets.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Feature Set: {fs_name} ({len(features)} features)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if len(features) == 0:\n",
    "        print(\"No features selected, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Prepare data with selected features\n",
    "    X_train_fs = X_train[features]\n",
    "    X_test_fs = X_test[features]\n",
    "    \n",
    "    # Clean feature names for LightGBM compatibility\n",
    "    X_train_fs_clean = clean_feature_names(X_train_fs)\n",
    "    X_test_fs_clean = clean_feature_names(X_test_fs)\n",
    "    \n",
    "    # LightGBM\n",
    "    print(\"\\nTraining LightGBM...\")\n",
    "    lgbm_model = LGBMClassifier(n_estimators=200, random_state=42, verbose=-1)\n",
    "    result = train_and_evaluate(lgbm_model, X_train_fs_clean, X_test_fs_clean, y_train, y_test, 'LightGBM')\n",
    "    result['Feature Set'] = fs_name\n",
    "    result['Num Features'] = len(features)\n",
    "    all_results.append(result)\n",
    "    print(f\"  Accuracy: {result['Accuracy']}, F1: {result['F1-Score']}, Time: {result['Training Time (s)']}s\")\n",
    "    \n",
    "    # XGBoost\n",
    "    print(\"Training XGBoost...\")\n",
    "    xgb_model = XGBClassifier(n_estimators=200, random_state=42, use_label_encoder=False, \n",
    "                               eval_metric='logloss', verbosity=0)\n",
    "    result = train_and_evaluate(xgb_model, X_train_fs, X_test_fs, y_train, y_test, 'XGBoost')\n",
    "    result['Feature Set'] = fs_name\n",
    "    result['Num Features'] = len(features)\n",
    "    all_results.append(result)\n",
    "    print(f\"  Accuracy: {result['Accuracy']}, F1: {result['F1-Score']}, Time: {result['Training Time (s)']}s\")\n",
    "    \n",
    "    # CatBoost\n",
    "    print(\"Training CatBoost...\")\n",
    "    cat_model = CatBoostClassifier(n_estimators=200, random_state=42, verbose=0)\n",
    "    result = train_and_evaluate(cat_model, X_train_fs, X_test_fs, y_train, y_test, 'CatBoost')\n",
    "    result['Feature Set'] = fs_name\n",
    "    result['Num Features'] = len(features)\n",
    "    all_results.append(result)\n",
    "    print(f\"  Accuracy: {result['Accuracy']}, F1: {result['F1-Score']}, Time: {result['Training Time (s)']}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL TRAINING COMPLETED!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd9bec",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d356c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "COMPLETE RESULTS TABLE\n",
      "====================================================================================================\n",
      " Feature Set  Num Features    Model  Accuracy  Precision  Recall  F1-Score  MCC  Training Time (s)\n",
      "All Features            57 LightGBM       1.0        1.0     1.0       1.0  1.0             3.7092\n",
      "All Features            57  XGBoost       1.0        1.0     1.0       1.0  1.0             2.6607\n",
      "All Features            57 CatBoost       1.0        1.0     1.0       1.0  1.0            17.9088\n",
      "      Boruta            52 LightGBM       1.0        1.0     1.0       1.0  1.0            20.9070\n",
      "      Boruta            52  XGBoost       1.0        1.0     1.0       1.0  1.0             3.2267\n",
      "      Boruta            52 CatBoost       1.0        1.0     1.0       1.0  1.0            12.2842\n",
      "         RFE            20 LightGBM       1.0        1.0     1.0       1.0  1.0             3.8918\n",
      "         RFE            20  XGBoost       1.0        1.0     1.0       1.0  1.0             1.9027\n",
      "         RFE            20 CatBoost       1.0        1.0     1.0       1.0  1.0            16.3676\n",
      " Correlation            39 LightGBM       1.0        1.0     1.0       1.0  1.0             6.1745\n",
      " Correlation            39  XGBoost       1.0        1.0     1.0       1.0  1.0            19.0364\n",
      " Correlation            39 CatBoost       1.0        1.0     1.0       1.0  1.0             9.7604\n",
      "    Ensemble             8 LightGBM       1.0        1.0     1.0       1.0  1.0             2.5944\n",
      "    Ensemble             8  XGBoost       1.0        1.0     1.0       1.0  1.0             1.3097\n",
      "    Ensemble             8 CatBoost       1.0        1.0     1.0       1.0  1.0             8.9671\n"
     ]
    }
   ],
   "source": [
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Reorder columns\n",
    "column_order = ['Feature Set', 'Num Features', 'Model', 'Accuracy', 'Precision', \n",
    "                'Recall', 'F1-Score', 'MCC', 'Training Time (s)']\n",
    "results_df = results_df[column_order]\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"COMPLETE RESULTS TABLE\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f532ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ACCURACY COMPARISON BY MODEL AND FEATURE SET\n",
      "====================================================================================================\n",
      "Model         CatBoost  LightGBM  XGBoost\n",
      "Feature Set                              \n",
      "All Features       1.0       1.0      1.0\n",
      "Boruta             1.0       1.0      1.0\n",
      "Correlation        1.0       1.0      1.0\n",
      "Ensemble           1.0       1.0      1.0\n",
      "RFE                1.0       1.0      1.0\n",
      "\n",
      "====================================================================================================\n",
      "F1-SCORE COMPARISON BY MODEL AND FEATURE SET\n",
      "====================================================================================================\n",
      "Model         CatBoost  LightGBM  XGBoost\n",
      "Feature Set                              \n",
      "All Features       1.0       1.0      1.0\n",
      "Boruta             1.0       1.0      1.0\n",
      "Correlation        1.0       1.0      1.0\n",
      "Ensemble           1.0       1.0      1.0\n",
      "RFE                1.0       1.0      1.0\n",
      "\n",
      "====================================================================================================\n",
      "TRAINING TIME COMPARISON BY MODEL AND FEATURE SET\n",
      "====================================================================================================\n",
      "Model         CatBoost  LightGBM  XGBoost\n",
      "Feature Set                              \n",
      "All Features   17.9088    3.7092   2.6607\n",
      "Boruta         12.2842   20.9070   3.2267\n",
      "Correlation     9.7604    6.1745  19.0364\n",
      "Ensemble        8.9671    2.5944   1.3097\n",
      "RFE            16.3676    3.8918   1.9027\n"
     ]
    }
   ],
   "source": [
    "# Pivot table for better visualization - by Model\n",
    "print(\"=\" * 100)\n",
    "print(\"ACCURACY COMPARISON BY MODEL AND FEATURE SET\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "accuracy_pivot = results_df.pivot(index='Feature Set', columns='Model', values='Accuracy')\n",
    "print(accuracy_pivot.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"F1-SCORE COMPARISON BY MODEL AND FEATURE SET\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "f1_pivot = results_df.pivot(index='Feature Set', columns='Model', values='F1-Score')\n",
    "print(f1_pivot.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TRAINING TIME COMPARISON BY MODEL AND FEATURE SET\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "time_pivot = results_df.pivot(index='Feature Set', columns='Model', values='Training Time (s)')\n",
    "print(time_pivot.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c551daba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "PERFORMANCE COMPARISON: SELECTED FEATURES vs ALL FEATURES\n",
      "====================================================================================================\n",
      "   Model Feature Set  Num Features Feature Reduction Accuracy Change F1 Change Time Reduction\n",
      "LightGBM      Boruta            52              8.8%         +0.0000   +0.0000        -463.7%\n",
      "LightGBM         RFE            20             64.9%         +0.0000   +0.0000          -4.9%\n",
      "LightGBM Correlation            39             31.6%         +0.0000   +0.0000         -66.5%\n",
      "LightGBM    Ensemble             8             86.0%         +0.0000   +0.0000          30.1%\n",
      " XGBoost      Boruta            52              8.8%         +0.0000   +0.0000         -21.3%\n",
      " XGBoost         RFE            20             64.9%         +0.0000   +0.0000          28.5%\n",
      " XGBoost Correlation            39             31.6%         +0.0000   +0.0000        -615.5%\n",
      " XGBoost    Ensemble             8             86.0%         +0.0000   +0.0000          50.8%\n",
      "CatBoost      Boruta            52              8.8%         +0.0000   +0.0000          31.4%\n",
      "CatBoost         RFE            20             64.9%         +0.0000   +0.0000           8.6%\n",
      "CatBoost Correlation            39             31.6%         +0.0000   +0.0000          45.5%\n",
      "CatBoost    Ensemble             8             86.0%         +0.0000   +0.0000          49.9%\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance change (selected features vs all features)\n",
    "print(\"=\" * 100)\n",
    "print(\"PERFORMANCE COMPARISON: SELECTED FEATURES vs ALL FEATURES\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for model in ['LightGBM', 'XGBoost', 'CatBoost']:\n",
    "    all_features_row = results_df[(results_df['Feature Set'] == 'All Features') & \n",
    "                                   (results_df['Model'] == model)].iloc[0]\n",
    "    \n",
    "    for fs in ['Boruta', 'RFE', 'Correlation', 'Ensemble']:\n",
    "        fs_row = results_df[(results_df['Feature Set'] == fs) & \n",
    "                            (results_df['Model'] == model)]\n",
    "        if len(fs_row) == 0:\n",
    "            continue\n",
    "        fs_row = fs_row.iloc[0]\n",
    "        \n",
    "        # Calculate changes\n",
    "        accuracy_change = fs_row['Accuracy'] - all_features_row['Accuracy']\n",
    "        f1_change = fs_row['F1-Score'] - all_features_row['F1-Score']\n",
    "        time_reduction = all_features_row['Training Time (s)'] - fs_row['Training Time (s)']\n",
    "        time_reduction_pct = (time_reduction / all_features_row['Training Time (s)']) * 100 if all_features_row['Training Time (s)'] > 0 else 0\n",
    "        feature_reduction = all_features_row['Num Features'] - fs_row['Num Features']\n",
    "        feature_reduction_pct = (feature_reduction / all_features_row['Num Features']) * 100\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'Model': model,\n",
    "            'Feature Set': fs,\n",
    "            'Num Features': fs_row['Num Features'],\n",
    "            'Feature Reduction': f\"{feature_reduction_pct:.1f}%\",\n",
    "            'Accuracy Change': f\"{accuracy_change:+.4f}\",\n",
    "            'F1 Change': f\"{f1_change:+.4f}\",\n",
    "            'Time Reduction': f\"{time_reduction_pct:.1f}%\"\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a0b51b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BEST CONFIGURATIONS\n",
      "====================================================================================================\n",
      "\n",
      "Best Accuracy: 1.0\n",
      "  Model: LightGBM\n",
      "  Feature Set: All Features (57 features)\n",
      "\n",
      "Best F1-Score: 1.0\n",
      "  Model: LightGBM\n",
      "  Feature Set: All Features (57 features)\n",
      "\n",
      "Best MCC: 1.0\n",
      "  Model: LightGBM\n",
      "  Feature Set: All Features (57 features)\n",
      "\n",
      "Best Efficiency (Accuracy/Time):\n",
      "  Model: XGBoost\n",
      "  Feature Set: Ensemble (8 features)\n",
      "  Accuracy: 1.0, Time: 1.3097s\n"
     ]
    }
   ],
   "source": [
    "# Find the best configuration\n",
    "print(\"=\" * 100)\n",
    "print(\"BEST CONFIGURATIONS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Best by Accuracy\n",
    "best_accuracy = results_df.loc[results_df['Accuracy'].idxmax()]\n",
    "print(f\"\\nBest Accuracy: {best_accuracy['Accuracy']}\")\n",
    "print(f\"  Model: {best_accuracy['Model']}\")\n",
    "print(f\"  Feature Set: {best_accuracy['Feature Set']} ({best_accuracy['Num Features']} features)\")\n",
    "\n",
    "# Best by F1-Score\n",
    "best_f1 = results_df.loc[results_df['F1-Score'].idxmax()]\n",
    "print(f\"\\nBest F1-Score: {best_f1['F1-Score']}\")\n",
    "print(f\"  Model: {best_f1['Model']}\")\n",
    "print(f\"  Feature Set: {best_f1['Feature Set']} ({best_f1['Num Features']} features)\")\n",
    "\n",
    "# Best by MCC\n",
    "best_mcc = results_df.loc[results_df['MCC'].idxmax()]\n",
    "print(f\"\\nBest MCC: {best_mcc['MCC']}\")\n",
    "print(f\"  Model: {best_mcc['Model']}\")\n",
    "print(f\"  Feature Set: {best_mcc['Feature Set']} ({best_mcc['Num Features']} features)\")\n",
    "\n",
    "# Best efficiency (high accuracy with low training time)\n",
    "# Create efficiency score: accuracy / training_time\n",
    "results_df['Efficiency'] = results_df['Accuracy'] / (results_df['Training Time (s)'] + 0.001)\n",
    "best_efficiency = results_df.loc[results_df['Efficiency'].idxmax()]\n",
    "print(f\"\\nBest Efficiency (Accuracy/Time):\")\n",
    "print(f\"  Model: {best_efficiency['Model']}\")\n",
    "print(f\"  Feature Set: {best_efficiency['Feature Set']} ({best_efficiency['Num Features']} features)\")\n",
    "print(f\"  Accuracy: {best_efficiency['Accuracy']}, Time: {best_efficiency['Training Time (s)']}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7583454",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Final Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd4acf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "FINAL SUMMARY AND RECOMMENDATIONS\n",
      "====================================================================================================\n",
      "\n",
      "FEATURE SELECTION ANALYSIS:\n",
      "\n",
      "1. Original Features: 57\n",
      "2. Boruta Selected: 52 (91.2% of original)\n",
      "3. RFE Selected: 20 (35.1% of original)\n",
      "4. Correlation Selected: 39 (68.4% of original)\n",
      "5. Ensemble Selected: 8 (14.0% of original)\n",
      "\n",
      "KEY FINDINGS:\n",
      "\n",
      "Average with ALL Features:\n",
      "  - Accuracy: 1.0000\n",
      "  - F1-Score: 1.0000\n",
      "  - Training Time: 8.0929s\n",
      "\n",
      "Average with SELECTED Features:\n",
      "  - Accuracy: 1.0000\n",
      "  - F1-Score: 1.0000\n",
      "  - Training Time: 8.8685s\n",
      "\n",
      "DIFFERENCE:\n",
      "  - Accuracy: +0.0000\n",
      "  - Training Time Reduction: -9.6%\n"
     ]
    }
   ],
   "source": [
    "# Final Summary\n",
    "print(\"=\" * 100)\n",
    "print(\"FINAL SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\"\"\n",
    "FEATURE SELECTION ANALYSIS:\n",
    "\"\"\")\n",
    "\n",
    "# Print feature selection summary\n",
    "print(f\"1. Original Features: {len(feature_cols)}\")\n",
    "print(f\"2. Boruta Selected: {len(boruta_features)} ({(len(boruta_features)/len(feature_cols)*100):.1f}% of original)\")\n",
    "print(f\"3. RFE Selected: {len(rfe_features)} ({(len(rfe_features)/len(feature_cols)*100):.1f}% of original)\")\n",
    "print(f\"4. Correlation Selected: {len(corr_features_final)} ({(len(corr_features_final)/len(feature_cols)*100):.1f}% of original)\")\n",
    "print(f\"5. Ensemble Selected: {len(ensemble_features)} ({(len(ensemble_features)/len(feature_cols)*100):.1f}% of original)\")\n",
    "\n",
    "print(\"\"\"\n",
    "KEY FINDINGS:\n",
    "\"\"\")\n",
    "\n",
    "# Calculate average metrics for all features vs selected features\n",
    "all_features_avg = results_df[results_df['Feature Set'] == 'All Features'][['Accuracy', 'F1-Score', 'Training Time (s)']].mean()\n",
    "selected_avg = results_df[results_df['Feature Set'] != 'All Features'][['Accuracy', 'F1-Score', 'Training Time (s)']].mean()\n",
    "\n",
    "print(f\"Average with ALL Features:\")\n",
    "print(f\"  - Accuracy: {all_features_avg['Accuracy']:.4f}\")\n",
    "print(f\"  - F1-Score: {all_features_avg['F1-Score']:.4f}\")\n",
    "print(f\"  - Training Time: {all_features_avg['Training Time (s)']:.4f}s\")\n",
    "\n",
    "print(f\"\\nAverage with SELECTED Features:\")\n",
    "print(f\"  - Accuracy: {selected_avg['Accuracy']:.4f}\")\n",
    "print(f\"  - F1-Score: {selected_avg['F1-Score']:.4f}\")\n",
    "print(f\"  - Training Time: {selected_avg['Training Time (s)']:.4f}s\")\n",
    "\n",
    "accuracy_diff = selected_avg['Accuracy'] - all_features_avg['Accuracy']\n",
    "time_diff = all_features_avg['Training Time (s)'] - selected_avg['Training Time (s)']\n",
    "time_diff_pct = (time_diff / all_features_avg['Training Time (s)']) * 100 if all_features_avg['Training Time (s)'] > 0 else 0\n",
    "\n",
    "print(f\"\\nDIFFERENCE:\")\n",
    "print(f\"  - Accuracy: {accuracy_diff:+.4f}\")\n",
    "print(f\"  - Training Time Reduction: {time_diff_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a39427d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: feature_selection_results.csv\n",
      "\n",
      "====================================================================================================\n",
      "FINAL RESULTS TABLE\n",
      "====================================================================================================\n",
      " Feature Set  Num Features    Model  Accuracy  Precision  Recall  F1-Score  MCC  Training Time (s)\n",
      "All Features            57 LightGBM       1.0        1.0     1.0       1.0  1.0             3.7092\n",
      "All Features            57  XGBoost       1.0        1.0     1.0       1.0  1.0             2.6607\n",
      "All Features            57 CatBoost       1.0        1.0     1.0       1.0  1.0            17.9088\n",
      "      Boruta            52 LightGBM       1.0        1.0     1.0       1.0  1.0            20.9070\n",
      "      Boruta            52  XGBoost       1.0        1.0     1.0       1.0  1.0             3.2267\n",
      "      Boruta            52 CatBoost       1.0        1.0     1.0       1.0  1.0            12.2842\n",
      "         RFE            20 LightGBM       1.0        1.0     1.0       1.0  1.0             3.8918\n",
      "         RFE            20  XGBoost       1.0        1.0     1.0       1.0  1.0             1.9027\n",
      "         RFE            20 CatBoost       1.0        1.0     1.0       1.0  1.0            16.3676\n",
      " Correlation            39 LightGBM       1.0        1.0     1.0       1.0  1.0             6.1745\n",
      " Correlation            39  XGBoost       1.0        1.0     1.0       1.0  1.0            19.0364\n",
      " Correlation            39 CatBoost       1.0        1.0     1.0       1.0  1.0             9.7604\n",
      "    Ensemble             8 LightGBM       1.0        1.0     1.0       1.0  1.0             2.5944\n",
      "    Ensemble             8  XGBoost       1.0        1.0     1.0       1.0  1.0             1.3097\n",
      "    Ensemble             8 CatBoost       1.0        1.0     1.0       1.0  1.0             8.9671\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "results_df.to_csv('feature_selection_results.csv', index=False)\n",
    "print(\"Results saved to: feature_selection_results.csv\")\n",
    "\n",
    "# Display final table\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"FINAL RESULTS TABLE\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df.drop(columns=['Efficiency']).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "algorithm_summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Algorithm Summary\n",
    "\n",
    "### Feature Selection Methods Comparison\n",
    "\n",
    "| Method | Type | Pros | Cons | Best For |\n",
    "|--------|------|------|------|----------|\n",
    "| **Boruta** | Wrapper | Comprehensive, statistical validation | Slow, computationally expensive | When you need robust feature selection |\n",
    "| **RFE** | Wrapper | Fast, model-specific selection | May miss non-linear relationships | Quick feature reduction |\n",
    "| **Correlation** | Filter | Very fast, interpretable | Only captures linear relationships | Initial exploration |\n",
    "| **Ensemble** | Hybrid | Robust across models, reduces bias | Requires multiple models | Production systems |\n",
    "\n",
    "### Key Features Identified\n",
    "\n",
    "1. **URLSimilarityIndex** - Most important feature across all methods\n",
    "2. **IsHTTPS** - Security indicator, important for phishing detection\n",
    "3. **HasSocialNet/HasCopyrightInfo** - Legitimacy indicators\n",
    "4. **LineOfCode/LargestLineLength** - Website complexity metrics\n",
    "5. **NoOfExternalRef** - External reference patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
