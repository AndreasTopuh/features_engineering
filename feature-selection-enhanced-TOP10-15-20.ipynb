{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b422771",
   "metadata": {},
   "source": [
    "# Feature Selection - Top 10, 15, 20 Features\n",
    "\n",
    "## Feature Selection Algorithms:\n",
    "- **Boruta** - Wrapper method using Random Forest\n",
    "- **RFE (Recursive Feature Elimination)** - Recursive elimination\n",
    "- **Correlation-based Feature Selection** - Filter method\n",
    "- **ContrastFS (Contrastive Feature Selection)** - Contrastive learning-based selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292985f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boruta in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: catboost in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boruta) (1.16.3)\n",
      "Requirement already satisfied: graphviz in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (3.10.6)\n",
      "Requirement already satisfied: plotly in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (6.5.2)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly->catboost) (2.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not available\n",
    "!pip install boruta lightgbm xgboost catboost scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b7cca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Models\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Boruta\n",
    "from boruta import BorutaPy\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aceb6f3",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3100bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATASET INFORMATION\n",
      "======================================================================\n",
      "Number of Rows: 235795\n",
      "Number of Columns: 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>URL</th>\n",
       "      <th>URLLength</th>\n",
       "      <th>Domain</th>\n",
       "      <th>DomainLength</th>\n",
       "      <th>IsDomainIP</th>\n",
       "      <th>TLD</th>\n",
       "      <th>URLSimilarityIndex</th>\n",
       "      <th>CharContinuationRate</th>\n",
       "      <th>TLDLegitimateProb</th>\n",
       "      <th>...</th>\n",
       "      <th>NoOfEmptyRef</th>\n",
       "      <th>NoOfExternalRef</th>\n",
       "      <th>has_no_www</th>\n",
       "      <th>num_slashes</th>\n",
       "      <th>num_hyphens</th>\n",
       "      <th>URL_Profanity_Prob</th>\n",
       "      <th>URL_NumberOf_Profanity</th>\n",
       "      <th>URLContent_Profanity_Prob</th>\n",
       "      <th>URLContent_NumberOf_Profanity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>521848.txt</td>\n",
       "      <td>https://www.southbankmosaics.com</td>\n",
       "      <td>32</td>\n",
       "      <td>www.southbankmosaics.com</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>com</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522907</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31372.txt</td>\n",
       "      <td>https://www.uni-mainz.de</td>\n",
       "      <td>24</td>\n",
       "      <td>www.uni-mainz.de</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>de</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.032650</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>597387.txt</td>\n",
       "      <td>https://www.voicefmradio.co.uk</td>\n",
       "      <td>30</td>\n",
       "      <td>www.voicefmradio.co.uk</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>uk</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.028555</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>554095.txt</td>\n",
       "      <td>https://www.sfnmjournal.com</td>\n",
       "      <td>27</td>\n",
       "      <td>www.sfnmjournal.com</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>com</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522907</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151578.txt</td>\n",
       "      <td>https://www.rewildingargentina.org</td>\n",
       "      <td>34</td>\n",
       "      <td>www.rewildingargentina.org</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>org</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079963</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FILENAME                                 URL  URLLength  \\\n",
       "0  521848.txt    https://www.southbankmosaics.com         32   \n",
       "1   31372.txt            https://www.uni-mainz.de         24   \n",
       "2  597387.txt      https://www.voicefmradio.co.uk         30   \n",
       "3  554095.txt         https://www.sfnmjournal.com         27   \n",
       "4  151578.txt  https://www.rewildingargentina.org         34   \n",
       "\n",
       "                       Domain  DomainLength  IsDomainIP  TLD  \\\n",
       "0    www.southbankmosaics.com            24           0  com   \n",
       "1            www.uni-mainz.de            16           0   de   \n",
       "2      www.voicefmradio.co.uk            22           0   uk   \n",
       "3         www.sfnmjournal.com            19           0  com   \n",
       "4  www.rewildingargentina.org            26           0  org   \n",
       "\n",
       "   URLSimilarityIndex  CharContinuationRate  TLDLegitimateProb  ...  \\\n",
       "0               100.0              1.000000           0.522907  ...   \n",
       "1               100.0              0.666667           0.032650  ...   \n",
       "2               100.0              0.866667           0.028555  ...   \n",
       "3               100.0              1.000000           0.522907  ...   \n",
       "4               100.0              1.000000           0.079963  ...   \n",
       "\n",
       "   NoOfEmptyRef  NoOfExternalRef  has_no_www  num_slashes  num_hyphens  \\\n",
       "0             0              124           0            2            0   \n",
       "1             0              217           0            2            1   \n",
       "2             2                5           0            2            0   \n",
       "3             1               31           0            2            0   \n",
       "4             1               85           0            2            0   \n",
       "\n",
       "   URL_Profanity_Prob  URL_NumberOf_Profanity  URLContent_Profanity_Prob  \\\n",
       "0            0.012189                       1                   0.011880   \n",
       "1            0.027988                       0                   0.019723   \n",
       "2            0.015063                       0                   0.000294   \n",
       "3            0.012189                       0                   0.000000   \n",
       "4            0.005476                       0                   0.002091   \n",
       "\n",
       "   URLContent_NumberOf_Profanity  label  \n",
       "0                              1      1  \n",
       "1                              0      1  \n",
       "2                              1      1  \n",
       "3                              0      1  \n",
       "4                             48      1  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with 63 features\n",
    "df = pd.read_csv('new_dataset/PhiUSIIL_Phishing_URL_63_Features.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Number of Rows: {len(df)}\")\n",
    "print(f\"Number of Columns: {len(df.columns)}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0f6b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column: label\n",
      "Target distribution:\n",
      "label\n",
      "1    134850\n",
      "0    100945\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "# Exclude non-feature columns (URL, FILENAME, etc.)\n",
    "exclude_cols = ['URL', 'FILENAME', 'Domain', 'TLD', 'Title']\n",
    "target_col = 'label'  # Adjust if your target column has different name\n",
    "\n",
    "# Find the target column\n",
    "if 'label' in df.columns:\n",
    "    target_col = 'label'\n",
    "elif 'Label' in df.columns:\n",
    "    target_col = 'Label'\n",
    "elif 'CLASS_LABEL' in df.columns:\n",
    "    target_col = 'CLASS_LABEL'\n",
    "else:\n",
    "    print(\"Target column not found! Please specify manually.\")\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "\n",
    "print(f\"Target column: {target_col}\")\n",
    "print(f\"Target distribution:\\n{df[target_col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f53e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature columns: 57\n",
      "\n",
      "Feature matrix shape: (235795, 57)\n",
      "Target vector shape: (235795,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature matrix X and target vector y\n",
    "# Get only numeric columns for features\n",
    "feature_cols = [col for col in df.columns \n",
    "                if col not in exclude_cols + [target_col] \n",
    "                and df[col].dtype in ['int64', 'float64', 'int32', 'float32']]\n",
    "\n",
    "print(f\"Number of feature columns: {len(feature_cols)}\")\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Encode target if needed\n",
    "if y.dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    print(f\"\\nTarget encoded: {le.classes_}\")\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe99c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA SPLIT\n",
      "======================================================================\n",
      "Training set: 188636 samples\n",
      "Test set: 47159 samples\n",
      "Number of features: 57\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA SPLIT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee06340",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Feature Selection Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c515c",
   "metadata": {},
   "source": [
    "### 2.1 Boruta Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6629406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BORUTA FEATURE SELECTION\n",
      "======================================================================\n",
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t57\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t49\n",
      "Tentative: \t8\n",
      "Rejected: \t0\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t50\n",
      "Tentative: \t7\n",
      "Rejected: \t0\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t51\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t5\n",
      "Rejected: \t0\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t52\n",
      "Tentative: \t4\n",
      "Rejected: \t1\n",
      "\n",
      "Boruta completed in 2029.06 seconds\n",
      "Selected 52 features out of 57\n"
     ]
    }
   ],
   "source": [
    "# Boruta Feature Selection\n",
    "print(\"=\" * 70)\n",
    "print(\"BORUTA FEATURE SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize Random Forest for Boruta\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5, random_state=42)\n",
    "\n",
    "# Initialize Boruta\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42, max_iter=100)\n",
    "\n",
    "# Fit Boruta\n",
    "start_time = time.time()\n",
    "boruta_selector.fit(X_train.values, y_train)\n",
    "boruta_time = time.time() - start_time\n",
    "\n",
    "# Get selected features\n",
    "boruta_features = X_train.columns[boruta_selector.support_].tolist()\n",
    "\n",
    "# Train RF to get importance scores\n",
    "rf_for_importance = RandomForestClassifier(n_jobs=-1, class_weight='balanced', \n",
    "                                            max_depth=5, random_state=42, n_estimators=100)\n",
    "rf_for_importance.fit(X_train, y_train)\n",
    "\n",
    "# Create importance scores\n",
    "boruta_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_for_importance.feature_importances_,\n",
    "    'boruta_rank': boruta_selector.ranking_,\n",
    "    'selected': boruta_selector.support_\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "boruta_importance_df = boruta_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nBoruta completed in {boruta_time:.2f} seconds\")\n",
    "print(f\"Selected {len(boruta_features)} features out of {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bbdd3c",
   "metadata": {},
   "source": [
    "### 2.2 RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b4953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RFE (RECURSIVE FEATURE ELIMINATION)\n",
      "======================================================================\n",
      "\n",
      "RFE completed in 123.02 seconds\n",
      "Selected 20 features out of 57\n"
     ]
    }
   ],
   "source": [
    "# RFE Feature Selection\n",
    "print(\"=\" * 70)\n",
    "print(\"RFE (RECURSIVE FEATURE ELIMINATION)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use LightGBM as base estimator for RFE\n",
    "lgbm_estimator = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "\n",
    "# Select top 20 features\n",
    "n_features_to_select = 20\n",
    "rfe_selector = RFE(estimator=lgbm_estimator, n_features_to_select=n_features_to_select, step=1)\n",
    "\n",
    "start_time = time.time()\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "rfe_time = time.time() - start_time\n",
    "\n",
    "# Get selected features\n",
    "rfe_features = X_train.columns[rfe_selector.support_].tolist()\n",
    "\n",
    "# Train LightGBM to get importance scores\n",
    "lgbm_for_importance = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "lgbm_for_importance.fit(X_train, y_train)\n",
    "\n",
    "rfe_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': lgbm_for_importance.feature_importances_,\n",
    "    'rfe_rank': rfe_selector.ranking_,\n",
    "    'selected': rfe_selector.support_\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "rfe_importance_df = rfe_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nRFE completed in {rfe_time:.2f} seconds\")\n",
    "print(f\"Selected {len(rfe_features)} features out of {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4c408",
   "metadata": {},
   "source": [
    "### 2.3 Correlation-based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1b3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CORRELATION-BASED FEATURE SELECTION\n",
      "======================================================================\n",
      "\n",
      "Correlation-based selection completed in 1.46 seconds\n",
      "Selected 39 features out of 57\n"
     ]
    }
   ],
   "source": [
    "# Correlation-based Feature Selection\n",
    "print(\"=\" * 70)\n",
    "print(\"CORRELATION-BASED FEATURE SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Calculate correlation with target\n",
    "correlations = pd.DataFrame()\n",
    "correlations['feature'] = feature_cols\n",
    "correlations['correlation'] = [abs(X_train[col].corr(pd.Series(y_train))) for col in feature_cols]\n",
    "correlations = correlations.sort_values('correlation', ascending=False)\n",
    "\n",
    "# Select features with correlation > threshold or top N features\n",
    "correlation_threshold = 0.1\n",
    "corr_features = correlations[correlations['correlation'] >= correlation_threshold]['feature'].tolist()\n",
    "\n",
    "# Also remove highly correlated features among themselves\n",
    "corr_matrix = X_train[corr_features].corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
    "corr_features_final = [f for f in corr_features if f not in to_drop]\n",
    "\n",
    "corr_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nCorrelation-based selection completed in {corr_time:.2f} seconds\")\n",
    "print(f\"Selected {len(corr_features_final)} features out of {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c05e2d",
   "metadata": {},
   "source": [
    "### 2.4 ContrastFS (Contrastive Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25576ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONTRASTFS (CONTRASTIVE FEATURE SELECTION)\n",
      "======================================================================\n",
      "\n",
      "ContrastFS completed in 0.06 seconds\n",
      "Selected 20 features out of 57\n"
     ]
    }
   ],
   "source": [
    "# ContrastFS (Contrastive Feature Selection)\n",
    "print(\"=\" * 70)\n",
    "print(\"CONTRASTFS (CONTRASTIVE FEATURE SELECTION)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def contrastfs_score(X, y, n_samples=5000):\n",
    "    \"\"\"\n",
    "    Calculate ContrastFS scores for each feature.\n",
    "    Contrast Score = inter-class distance / intra-class distance\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Sample data for efficiency (large datasets)\n",
    "    if len(X) > n_samples:\n",
    "        np.random.seed(42)\n",
    "        indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "        X_sample = X.iloc[indices].values\n",
    "        y_sample = np.array(y)[indices] if hasattr(y, '__iter__') else y.iloc[indices].values\n",
    "    else:\n",
    "        X_sample = X.values\n",
    "        y_sample = np.array(y)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_sample)\n",
    "    \n",
    "    # Get unique classes\n",
    "    classes = np.unique(y_sample)\n",
    "    n_features = X_scaled.shape[1]\n",
    "    \n",
    "    contrast_scores = []\n",
    "    \n",
    "    for feat_idx in range(n_features):\n",
    "        feature_values = X_scaled[:, feat_idx]\n",
    "        \n",
    "        # Calculate intra-class variance\n",
    "        intra_class_var = 0\n",
    "        for c in classes:\n",
    "            class_mask = (y_sample == c)\n",
    "            class_values = feature_values[class_mask]\n",
    "            if len(class_values) > 1:\n",
    "                intra_class_var += np.var(class_values) * len(class_values)\n",
    "        intra_class_var /= len(y_sample)\n",
    "        \n",
    "        # Calculate inter-class distance\n",
    "        class_means = []\n",
    "        class_sizes = []\n",
    "        for c in classes:\n",
    "            class_mask = (y_sample == c)\n",
    "            class_values = feature_values[class_mask]\n",
    "            class_means.append(np.mean(class_values))\n",
    "            class_sizes.append(len(class_values))\n",
    "        \n",
    "        # Weighted inter-class distance\n",
    "        inter_class_dist = 0\n",
    "        total_pairs = 0\n",
    "        for i in range(len(classes)):\n",
    "            for j in range(i + 1, len(classes)):\n",
    "                weight = class_sizes[i] * class_sizes[j]\n",
    "                inter_class_dist += weight * (class_means[i] - class_means[j]) ** 2\n",
    "                total_pairs += weight\n",
    "        \n",
    "        if total_pairs > 0:\n",
    "            inter_class_dist /= total_pairs\n",
    "        \n",
    "        # Contrast Score\n",
    "        epsilon = 1e-10\n",
    "        contrast_score = inter_class_dist / (intra_class_var + epsilon)\n",
    "        contrast_scores.append(contrast_score)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'contrast_score': contrast_scores\n",
    "    })\n",
    "    results_df = results_df.sort_values('contrast_score', ascending=False)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Apply ContrastFS\n",
    "contrastfs_df = contrastfs_score(X_train, y_train, n_samples=10000)\n",
    "\n",
    "# Normalize scores to [0, 1]\n",
    "contrastfs_df['normalized_score'] = contrastfs_df['contrast_score'] / contrastfs_df['contrast_score'].max()\n",
    "\n",
    "# Select top 20 features\n",
    "n_top_features = 20\n",
    "contrastfs_features = contrastfs_df.head(n_top_features)['feature'].tolist()\n",
    "\n",
    "contrastfs_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nContrastFS completed in {contrastfs_time:.2f} seconds\")\n",
    "print(f\"Selected {len(contrastfs_features)} features out of {X_train.shape[1]}\")\n",
    "\n",
    "# Store for later comparison\n",
    "contrast_features = contrastfs_features\n",
    "contrast_time = contrastfs_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda10967",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Top 10, Top 15, Top 20 Features per Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "top_features_display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "BORUTA (Random Forest Importance) - TOP FEATURES\n",
      "================================================================================\n",
      "\n",
      "üìå TOP 10:\n",
      "   1. URLSimilarityIndex\n",
      "   2. LineOfCode\n",
      "   3. NoOfExternalRef\n",
      "   4. NoOfSelfRef\n",
      "   5. NoOfJS\n",
      "   6. HasDescription\n",
      "   7. NoOfImage\n",
      "   8. HasSocialNet\n",
      "   9. NoOfCSS\n",
      "  10. HasCopyrightInfo\n",
      "\n",
      "üìå TOP 15:\n",
      "   1. URLSimilarityIndex\n",
      "   2. LineOfCode\n",
      "   3. NoOfExternalRef\n",
      "   4. NoOfSelfRef\n",
      "   5. NoOfJS\n",
      "   6. HasDescription\n",
      "   7. NoOfImage\n",
      "   8. HasSocialNet\n",
      "   9. NoOfCSS\n",
      "  10. HasCopyrightInfo\n",
      "  11. has_no_www ‚¨ÖÔ∏è (NEW)\n",
      "  12. LargestLineLength ‚¨ÖÔ∏è (NEW)\n",
      "  13. IsHTTPS ‚¨ÖÔ∏è (NEW)\n",
      "  14. num_slashes ‚¨ÖÔ∏è (NEW)\n",
      "  15. DomainTitleMatchScore ‚¨ÖÔ∏è (NEW)\n",
      "\n",
      "üìå TOP 20:\n",
      "   1. URLSimilarityIndex\n",
      "   2. LineOfCode\n",
      "   3. NoOfExternalRef\n",
      "   4. NoOfSelfRef\n",
      "   5. NoOfJS\n",
      "   6. HasDescription\n",
      "   7. NoOfImage\n",
      "   8. HasSocialNet\n",
      "   9. NoOfCSS\n",
      "  10. HasCopyrightInfo\n",
      "  11. has_no_www\n",
      "  12. LargestLineLength\n",
      "  13. IsHTTPS\n",
      "  14. num_slashes\n",
      "  15. DomainTitleMatchScore\n",
      "  16. NoOfOtherSpecialCharsInURL ‚¨ÖÔ∏è (NEW)\n",
      "  17. NoOfiFrame ‚¨ÖÔ∏è (NEW)\n",
      "  18. SpacialCharRatioInURL ‚¨ÖÔ∏è (NEW)\n",
      "  19. URLContent_NumberOf_Profanity ‚¨ÖÔ∏è (NEW)\n",
      "  20. NoOfDegitsInURL ‚¨ÖÔ∏è (NEW)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RFE (LightGBM Importance) - TOP FEATURES\n",
      "================================================================================\n",
      "\n",
      "üìå TOP 10:\n",
      "   1. LineOfCode\n",
      "   2. LargestLineLength\n",
      "   3. NoOfExternalRef\n",
      "   4. URLCharProb\n",
      "   5. LetterRatioInURL\n",
      "   6. SpacialCharRatioInURL\n",
      "   7. IsHTTPS\n",
      "   8. URLLength\n",
      "   9. NoOfJS\n",
      "  10. URLSimilarityIndex\n",
      "\n",
      "üìå TOP 15:\n",
      "   1. LineOfCode\n",
      "   2. LargestLineLength\n",
      "   3. NoOfExternalRef\n",
      "   4. URLCharProb\n",
      "   5. LetterRatioInURL\n",
      "   6. SpacialCharRatioInURL\n",
      "   7. IsHTTPS\n",
      "   8. URLLength\n",
      "   9. NoOfJS\n",
      "  10. URLSimilarityIndex\n",
      "  11. NoOfCSS ‚¨ÖÔ∏è (NEW)\n",
      "  12. URL_Profanity_Prob ‚¨ÖÔ∏è (NEW)\n",
      "  13. NoOfLettersInURL ‚¨ÖÔ∏è (NEW)\n",
      "  14. NoOfSelfRef ‚¨ÖÔ∏è (NEW)\n",
      "  15. NoOfSubDomain ‚¨ÖÔ∏è (NEW)\n",
      "\n",
      "üìå TOP 20:\n",
      "   1. LineOfCode\n",
      "   2. LargestLineLength\n",
      "   3. NoOfExternalRef\n",
      "   4. URLCharProb\n",
      "   5. LetterRatioInURL\n",
      "   6. SpacialCharRatioInURL\n",
      "   7. IsHTTPS\n",
      "   8. URLLength\n",
      "   9. NoOfJS\n",
      "  10. URLSimilarityIndex\n",
      "  11. NoOfCSS\n",
      "  12. URL_Profanity_Prob\n",
      "  13. NoOfLettersInURL\n",
      "  14. NoOfSelfRef\n",
      "  15. NoOfSubDomain\n",
      "  16. NoOfEmptyRef ‚¨ÖÔ∏è (NEW)\n",
      "  17. NoOfImage ‚¨ÖÔ∏è (NEW)\n",
      "  18. CharContinuationRate ‚¨ÖÔ∏è (NEW)\n",
      "  19. HasDescription ‚¨ÖÔ∏è (NEW)\n",
      "  20. URLContent_Profanity_Prob ‚¨ÖÔ∏è (NEW)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CORRELATION-BASED - TOP FEATURES\n",
      "================================================================================\n",
      "\n",
      "üìå TOP 10:\n",
      "   1. URLSimilarityIndex\n",
      "   2. HasSocialNet\n",
      "   3. HasCopyrightInfo\n",
      "   4. HasDescription\n",
      "   5. has_no_www\n",
      "   6. IsHTTPS\n",
      "   7. DomainTitleMatchScore\n",
      "   8. HasSubmitButton\n",
      "   9. IsResponsive\n",
      "  10. URLTitleMatchScore\n",
      "\n",
      "üìå TOP 15:\n",
      "   1. URLSimilarityIndex\n",
      "   2. HasSocialNet\n",
      "   3. HasCopyrightInfo\n",
      "   4. HasDescription\n",
      "   5. has_no_www\n",
      "   6. IsHTTPS\n",
      "   7. DomainTitleMatchScore\n",
      "   8. HasSubmitButton\n",
      "   9. IsResponsive\n",
      "  10. URLTitleMatchScore\n",
      "  11. SpacialCharRatioInURL ‚¨ÖÔ∏è (NEW)\n",
      "  12. HasHiddenFields ‚¨ÖÔ∏è (NEW)\n",
      "  13. HasFavicon ‚¨ÖÔ∏è (NEW)\n",
      "  14. num_slashes ‚¨ÖÔ∏è (NEW)\n",
      "  15. URLCharProb ‚¨ÖÔ∏è (NEW)\n",
      "\n",
      "üìå TOP 20:\n",
      "   1. URLSimilarityIndex\n",
      "   2. HasSocialNet\n",
      "   3. HasCopyrightInfo\n",
      "   4. HasDescription\n",
      "   5. has_no_www\n",
      "   6. IsHTTPS\n",
      "   7. DomainTitleMatchScore\n",
      "   8. HasSubmitButton\n",
      "   9. IsResponsive\n",
      "  10. URLTitleMatchScore\n",
      "  11. SpacialCharRatioInURL\n",
      "  12. HasHiddenFields\n",
      "  13. HasFavicon\n",
      "  14. num_slashes\n",
      "  15. URLCharProb\n",
      "  16. CharContinuationRate ‚¨ÖÔ∏è (NEW)\n",
      "  17. HasTitle ‚¨ÖÔ∏è (NEW)\n",
      "  18. DegitRatioInURL ‚¨ÖÔ∏è (NEW)\n",
      "  19. Robots ‚¨ÖÔ∏è (NEW)\n",
      "  20. LetterRatioInURL ‚¨ÖÔ∏è (NEW)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CONTRASTFS (Contrastive Selection) - TOP FEATURES\n",
      "================================================================================\n",
      "\n",
      "üìå TOP 10:\n",
      "   1. URLSimilarityIndex\n",
      "   2. HasSocialNet\n",
      "   3. HasCopyrightInfo\n",
      "   4. HasDescription\n",
      "   5. has_no_www\n",
      "   6. IsHTTPS\n",
      "   7. HasSubmitButton\n",
      "   8. DomainTitleMatchScore\n",
      "   9. IsResponsive\n",
      "  10. URLTitleMatchScore\n",
      "\n",
      "üìå TOP 15:\n",
      "   1. URLSimilarityIndex\n",
      "   2. HasSocialNet\n",
      "   3. HasCopyrightInfo\n",
      "   4. HasDescription\n",
      "   5. has_no_www\n",
      "   6. IsHTTPS\n",
      "   7. HasSubmitButton\n",
      "   8. DomainTitleMatchScore\n",
      "   9. IsResponsive\n",
      "  10. URLTitleMatchScore\n",
      "  11. SpacialCharRatioInURL ‚¨ÖÔ∏è (NEW)\n",
      "  12. HasHiddenFields ‚¨ÖÔ∏è (NEW)\n",
      "  13. num_slashes ‚¨ÖÔ∏è (NEW)\n",
      "  14. HasFavicon ‚¨ÖÔ∏è (NEW)\n",
      "  15. URLCharProb ‚¨ÖÔ∏è (NEW)\n",
      "\n",
      "üìå TOP 20:\n",
      "   1. URLSimilarityIndex\n",
      "   2. HasSocialNet\n",
      "   3. HasCopyrightInfo\n",
      "   4. HasDescription\n",
      "   5. has_no_www\n",
      "   6. IsHTTPS\n",
      "   7. HasSubmitButton\n",
      "   8. DomainTitleMatchScore\n",
      "   9. IsResponsive\n",
      "  10. URLTitleMatchScore\n",
      "  11. SpacialCharRatioInURL\n",
      "  12. HasHiddenFields\n",
      "  13. num_slashes\n",
      "  14. HasFavicon\n",
      "  15. URLCharProb\n",
      "  16. CharContinuationRate ‚¨ÖÔ∏è (NEW)\n",
      "  17. HasTitle ‚¨ÖÔ∏è (NEW)\n",
      "  18. DegitRatioInURL ‚¨ÖÔ∏è (NEW)\n",
      "  19. NoOfCSS ‚¨ÖÔ∏è (NEW)\n",
      "  20. Robots ‚¨ÖÔ∏è (NEW)\n"
     ]
    }
   ],
   "source": [
    "# Display Top 10, 15, 20 Features for Each Method\n",
    "\n",
    "def display_top_features(importance_df, method_name, feature_col='feature'):\n",
    "    \"\"\"Display Top 10, 15, 20 features with incremental info for Top 15\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{method_name} - TOP FEATURES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Get Top 10, 15, 20\n",
    "    top10 = importance_df.head(10)[feature_col].tolist()\n",
    "    top15 = importance_df.head(15)[feature_col].tolist()\n",
    "    top20 = importance_df.head(20)[feature_col].tolist()\n",
    "    \n",
    "    # Top 10\n",
    "    print(\"\\nüìå TOP 10:\")\n",
    "    for i, f in enumerate(top10, 1):\n",
    "        print(f\"  {i:2}. {f}\")\n",
    "    \n",
    "    # Top 15 - show which 5 are additional\n",
    "    additional_5 = [f for f in top15 if f not in top10]\n",
    "    print(\"\\nüìå TOP 15:\")\n",
    "    for i, f in enumerate(top15, 1):\n",
    "        marker = \" ‚¨ÖÔ∏è (NEW)\" if f in additional_5 else \"\"\n",
    "        print(f\"  {i:2}. {f}{marker}\")\n",
    "    \n",
    "    # Top 20 - show which 5 are additional from top 15\n",
    "    additional_5_from_15 = [f for f in top20 if f not in top15]\n",
    "    print(\"\\nüìå TOP 20:\")\n",
    "    for i, f in enumerate(top20, 1):\n",
    "        marker = \" ‚¨ÖÔ∏è (NEW)\" if f in additional_5_from_15 else \"\"\n",
    "        print(f\"  {i:2}. {f}{marker}\")\n",
    "    \n",
    "    return {'top10': top10, 'top15': top15, 'top20': top20}\n",
    "\n",
    "# Display for each method\n",
    "print(\"\\n\")\n",
    "boruta_tops = display_top_features(boruta_importance_df, \"BORUTA (Random Forest Importance)\")\n",
    "print(\"\\n\")\n",
    "rfe_tops = display_top_features(rfe_importance_df, \"RFE (LightGBM Importance)\")\n",
    "print(\"\\n\")\n",
    "corr_tops = display_top_features(correlations, \"CORRELATION-BASED\", feature_col='feature')\n",
    "print(\"\\n\")\n",
    "contrast_tops = display_top_features(contrastfs_df, \"CONTRASTFS (Contrastive Selection)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Feature Selection Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce821b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE SELECTION SUMMARY\n",
      "======================================================================\n",
      "           Method  Num Features  Selection Time (s)\n",
      "     All Features            57                0.00\n",
      "           Boruta            52             2029.06\n",
      "              RFE            20              123.02\n",
      "Correlation-based            39                1.46\n",
      "       ContrastFS            20                0.06\n",
      "\n",
      "Common features across all methods: 6\n",
      "  - CharContinuationRate\n",
      "  - URLCharProb\n",
      "  - URLSimilarityIndex\n",
      "  - IsHTTPS\n",
      "  - HasDescription\n",
      "  - SpacialCharRatioInURL\n"
     ]
    }
   ],
   "source": [
    "# Summary of all feature selection methods\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE SELECTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "selection_summary = {\n",
    "    'Method': ['All Features', 'Boruta', 'RFE', 'Correlation-based', 'ContrastFS'],\n",
    "    'Num Features': [\n",
    "        len(feature_cols),\n",
    "        len(boruta_features),\n",
    "        len(rfe_features),\n",
    "        len(corr_features_final),\n",
    "        len(contrast_features)\n",
    "    ],\n",
    "    'Selection Time (s)': [\n",
    "        0,\n",
    "        round(boruta_time, 2),\n",
    "        round(rfe_time, 2),\n",
    "        round(corr_time, 2),\n",
    "        round(contrast_time, 2)\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(selection_summary)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Find common features across all methods\n",
    "common_features = set(boruta_features) & set(rfe_features) & set(corr_features_final) & set(contrast_features)\n",
    "print(f\"\\nCommon features across all methods: {len(common_features)}\")\n",
    "for f in common_features:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_table",
   "metadata": {},
   "source": [
    "### Top 10, 15, 20 Comparison Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comparison_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "TOP 10 FEATURES COMPARISON\n",
      "====================================================================================================\n",
      " Rank             Boruta                   RFE           Correlation            ContrastFS\n",
      "    1 URLSimilarityIndex            LineOfCode    URLSimilarityIndex    URLSimilarityIndex\n",
      "    2         LineOfCode     LargestLineLength          HasSocialNet          HasSocialNet\n",
      "    3    NoOfExternalRef       NoOfExternalRef      HasCopyrightInfo      HasCopyrightInfo\n",
      "    4        NoOfSelfRef           URLCharProb        HasDescription        HasDescription\n",
      "    5             NoOfJS      LetterRatioInURL            has_no_www            has_no_www\n",
      "    6     HasDescription SpacialCharRatioInURL               IsHTTPS               IsHTTPS\n",
      "    7          NoOfImage               IsHTTPS DomainTitleMatchScore       HasSubmitButton\n",
      "    8       HasSocialNet             URLLength       HasSubmitButton DomainTitleMatchScore\n",
      "    9            NoOfCSS                NoOfJS          IsResponsive          IsResponsive\n",
      "   10   HasCopyrightInfo    URLSimilarityIndex    URLTitleMatchScore    URLTitleMatchScore\n",
      "\n",
      "====================================================================================================\n",
      "TOP 15 FEATURES COMPARISON\n",
      "====================================================================================================\n",
      " Rank                Boruta                   RFE           Correlation            ContrastFS\n",
      "    1    URLSimilarityIndex            LineOfCode    URLSimilarityIndex    URLSimilarityIndex\n",
      "    2            LineOfCode     LargestLineLength          HasSocialNet          HasSocialNet\n",
      "    3       NoOfExternalRef       NoOfExternalRef      HasCopyrightInfo      HasCopyrightInfo\n",
      "    4           NoOfSelfRef           URLCharProb        HasDescription        HasDescription\n",
      "    5                NoOfJS      LetterRatioInURL            has_no_www            has_no_www\n",
      "    6        HasDescription SpacialCharRatioInURL               IsHTTPS               IsHTTPS\n",
      "    7             NoOfImage               IsHTTPS DomainTitleMatchScore       HasSubmitButton\n",
      "    8          HasSocialNet             URLLength       HasSubmitButton DomainTitleMatchScore\n",
      "    9               NoOfCSS                NoOfJS          IsResponsive          IsResponsive\n",
      "   10      HasCopyrightInfo    URLSimilarityIndex    URLTitleMatchScore    URLTitleMatchScore\n",
      "   11            has_no_www               NoOfCSS SpacialCharRatioInURL SpacialCharRatioInURL\n",
      "   12     LargestLineLength    URL_Profanity_Prob       HasHiddenFields       HasHiddenFields\n",
      "   13               IsHTTPS      NoOfLettersInURL            HasFavicon           num_slashes\n",
      "   14           num_slashes           NoOfSelfRef           num_slashes            HasFavicon\n",
      "   15 DomainTitleMatchScore         NoOfSubDomain           URLCharProb           URLCharProb\n",
      "\n",
      "====================================================================================================\n",
      "TOP 20 FEATURES COMPARISON\n",
      "====================================================================================================\n",
      " Rank                        Boruta                       RFE           Correlation            ContrastFS\n",
      "    1            URLSimilarityIndex                LineOfCode    URLSimilarityIndex    URLSimilarityIndex\n",
      "    2                    LineOfCode         LargestLineLength          HasSocialNet          HasSocialNet\n",
      "    3               NoOfExternalRef           NoOfExternalRef      HasCopyrightInfo      HasCopyrightInfo\n",
      "    4                   NoOfSelfRef               URLCharProb        HasDescription        HasDescription\n",
      "    5                        NoOfJS          LetterRatioInURL            has_no_www            has_no_www\n",
      "    6                HasDescription     SpacialCharRatioInURL               IsHTTPS               IsHTTPS\n",
      "    7                     NoOfImage                   IsHTTPS DomainTitleMatchScore       HasSubmitButton\n",
      "    8                  HasSocialNet                 URLLength       HasSubmitButton DomainTitleMatchScore\n",
      "    9                       NoOfCSS                    NoOfJS          IsResponsive          IsResponsive\n",
      "   10              HasCopyrightInfo        URLSimilarityIndex    URLTitleMatchScore    URLTitleMatchScore\n",
      "   11                    has_no_www                   NoOfCSS SpacialCharRatioInURL SpacialCharRatioInURL\n",
      "   12             LargestLineLength        URL_Profanity_Prob       HasHiddenFields       HasHiddenFields\n",
      "   13                       IsHTTPS          NoOfLettersInURL            HasFavicon           num_slashes\n",
      "   14                   num_slashes               NoOfSelfRef           num_slashes            HasFavicon\n",
      "   15         DomainTitleMatchScore             NoOfSubDomain           URLCharProb           URLCharProb\n",
      "   16    NoOfOtherSpecialCharsInURL              NoOfEmptyRef  CharContinuationRate  CharContinuationRate\n",
      "   17                    NoOfiFrame                 NoOfImage              HasTitle              HasTitle\n",
      "   18         SpacialCharRatioInURL      CharContinuationRate       DegitRatioInURL       DegitRatioInURL\n",
      "   19 URLContent_NumberOf_Profanity            HasDescription                Robots               NoOfCSS\n",
      "   20               NoOfDegitsInURL URLContent_Profanity_Prob      LetterRatioInURL                Robots\n"
     ]
    }
   ],
   "source": [
    "# Create comparison tables for Top 10, 15, 20\n",
    "\n",
    "def create_comparison_table(n_top):\n",
    "    \"\"\"Create comparison table for specified top N features\"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'Rank': range(1, n_top + 1),\n",
    "        'Boruta': boruta_importance_df.head(n_top)['feature'].values,\n",
    "        'RFE': rfe_importance_df.head(n_top)['feature'].values,\n",
    "        'Correlation': correlations.head(n_top)['feature'].values,\n",
    "        'ContrastFS': contrastfs_df.head(n_top)['feature'].values\n",
    "    })\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"TOP 10 FEATURES COMPARISON\")\n",
    "print(\"=\" * 100)\n",
    "top10_table = create_comparison_table(10)\n",
    "print(top10_table.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TOP 15 FEATURES COMPARISON\")\n",
    "print(\"=\" * 100)\n",
    "top15_table = create_comparison_table(15)\n",
    "print(top15_table.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TOP 20 FEATURES COMPARISON\")\n",
    "print(\"=\" * 100)\n",
    "top20_table = create_comparison_table(20)\n",
    "print(top20_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export_section",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Export Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "export_csv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPORT COMPLETED\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Saved to: TopFeaturesSelectionAll.csv\n",
      "\n",
      "File contains 20 rows with Top 10, 15, 20 features from all 4 methods.\n",
      "\n",
      "Preview:\n",
      " Rank Top_Category                Boruta_Feature  Boruta_Score               RFE_Feature  RFE_Score   Correlation_Feature  Correlation_Score    ContrastFS_Feature  ContrastFS_Score\n",
      "    1        Top10            URLSimilarityIndex      0.216753                LineOfCode        499    URLSimilarityIndex           0.860443    URLSimilarityIndex          1.000000\n",
      "    2        Top10                    LineOfCode      0.154901         LargestLineLength        471          HasSocialNet           0.783682          HasSocialNet          0.570522\n",
      "    3        Top10               NoOfExternalRef      0.115893           NoOfExternalRef        277      HasCopyrightInfo           0.742820      HasCopyrightInfo          0.456686\n",
      "    4        Top10                   NoOfSelfRef      0.093042               URLCharProb        269        HasDescription           0.690587        HasDescription          0.331348\n",
      "    5        Top10                        NoOfJS      0.056995          LetterRatioInURL        242            has_no_www           0.668396            has_no_www          0.303484\n",
      "    6        Top10                HasDescription      0.055622     SpacialCharRatioInURL        180               IsHTTPS           0.612900               IsHTTPS          0.225578\n",
      "    7        Top10                     NoOfImage      0.047761                   IsHTTPS        161 DomainTitleMatchScore           0.583463       HasSubmitButton          0.187544\n",
      "    8        Top10                  HasSocialNet      0.035257                 URLLength        128       HasSubmitButton           0.578994 DomainTitleMatchScore          0.187240\n",
      "    9        Top10                       NoOfCSS      0.032141                    NoOfJS        104          IsResponsive           0.548483          IsResponsive          0.164746\n",
      "   10        Top10              HasCopyrightInfo      0.030206        URLSimilarityIndex        102    URLTitleMatchScore           0.538363    URLTitleMatchScore          0.145716\n",
      "   11        Top15                    has_no_www      0.020230                   NoOfCSS         92 SpacialCharRatioInURL           0.533748 SpacialCharRatioInURL          0.136555\n",
      "   12        Top15             LargestLineLength      0.019679        URL_Profanity_Prob         85       HasHiddenFields           0.507307       HasHiddenFields          0.122398\n",
      "   13        Top15                       IsHTTPS      0.019369          NoOfLettersInURL         85            HasFavicon           0.493375           num_slashes          0.112155\n",
      "   14        Top15                   num_slashes      0.016156               NoOfSelfRef         79           num_slashes           0.479851            HasFavicon          0.112077\n",
      "   15        Top15         DomainTitleMatchScore      0.015589             NoOfSubDomain         63           URLCharProb           0.470242           URLCharProb          0.099307\n",
      "   16        Top20    NoOfOtherSpecialCharsInURL      0.015196              NoOfEmptyRef         40  CharContinuationRate           0.467198  CharContinuationRate          0.098041\n",
      "   17        Top20                    NoOfiFrame      0.012101                 NoOfImage         36              HasTitle           0.459890              HasTitle          0.097084\n",
      "   18        Top20         SpacialCharRatioInURL      0.008550      CharContinuationRate         19       DegitRatioInURL           0.432309       DegitRatioInURL          0.085663\n",
      "   19        Top20 URLContent_NumberOf_Profanity      0.003671            HasDescription         16                Robots           0.393578               NoOfCSS          0.071919\n",
      "   20        Top20               NoOfDegitsInURL      0.003539 URLContent_Profanity_Prob         14      LetterRatioInURL           0.368522                Robots          0.063701\n"
     ]
    }
   ],
   "source": [
    "# Export all Top Features to CSV: TopFeaturesSelectionAll.csv\n",
    "\n",
    "# Create comprehensive DataFrame with all methods and all top rankings\n",
    "max_features = 20\n",
    "\n",
    "# Prepare data for export\n",
    "export_data = {\n",
    "    'Rank': list(range(1, max_features + 1)),\n",
    "    'Boruta_Feature': boruta_importance_df.head(max_features)['feature'].values.tolist(),\n",
    "    'Boruta_Score': boruta_importance_df.head(max_features)['importance'].round(6).values.tolist(),\n",
    "    'RFE_Feature': rfe_importance_df.head(max_features)['feature'].values.tolist(),\n",
    "    'RFE_Score': rfe_importance_df.head(max_features)['importance'].values.tolist(),\n",
    "    'Correlation_Feature': correlations.head(max_features)['feature'].values.tolist(),\n",
    "    'Correlation_Score': correlations.head(max_features)['correlation'].round(6).values.tolist(),\n",
    "    'ContrastFS_Feature': contrastfs_df.head(max_features)['feature'].values.tolist(),\n",
    "    'ContrastFS_Score': contrastfs_df.head(max_features)['normalized_score'].round(6).values.tolist(),\n",
    "}\n",
    "\n",
    "# Add Top category column\n",
    "top_category = []\n",
    "for i in range(1, max_features + 1):\n",
    "    if i <= 10:\n",
    "        top_category.append('Top10')\n",
    "    elif i <= 15:\n",
    "        top_category.append('Top15')\n",
    "    else:\n",
    "        top_category.append('Top20')\n",
    "\n",
    "export_data['Top_Category'] = top_category\n",
    "\n",
    "# Create DataFrame\n",
    "export_df = pd.DataFrame(export_data)\n",
    "\n",
    "# Reorder columns\n",
    "export_df = export_df[['Rank', 'Top_Category', \n",
    "                        'Boruta_Feature', 'Boruta_Score',\n",
    "                        'RFE_Feature', 'RFE_Score',\n",
    "                        'Correlation_Feature', 'Correlation_Score',\n",
    "                        'ContrastFS_Feature', 'ContrastFS_Score']]\n",
    "\n",
    "# Save to CSV\n",
    "output_filename = 'TopFeaturesSelectionAll.csv'\n",
    "export_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXPORT COMPLETED\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n‚úÖ Saved to: {output_filename}\")\n",
    "print(f\"\\nFile contains {len(export_df)} rows with Top 10, 15, 20 features from all 4 methods.\")\n",
    "print(\"\\nPreview:\")\n",
    "print(export_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "final_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOP 15 ADDITIONAL FEATURES (5 new features compared to Top 10)\n",
      "================================================================================\n",
      "\n",
      "üìå Boruta - 5 Additional Features (Rank 11-15):\n",
      "   11. has_no_www\n",
      "   12. LargestLineLength\n",
      "   13. IsHTTPS\n",
      "   14. num_slashes\n",
      "   15. DomainTitleMatchScore\n",
      "\n",
      "üìå RFE - 5 Additional Features (Rank 11-15):\n",
      "   11. NoOfCSS\n",
      "   12. URL_Profanity_Prob\n",
      "   13. NoOfLettersInURL\n",
      "   14. NoOfSelfRef\n",
      "   15. NoOfSubDomain\n",
      "\n",
      "üìå Correlation - 5 Additional Features (Rank 11-15):\n",
      "   11. SpacialCharRatioInURL\n",
      "   12. HasHiddenFields\n",
      "   13. HasFavicon\n",
      "   14. num_slashes\n",
      "   15. URLCharProb\n",
      "\n",
      "üìå ContrastFS - 5 Additional Features (Rank 11-15):\n",
      "   11. SpacialCharRatioInURL\n",
      "   12. HasHiddenFields\n",
      "   13. num_slashes\n",
      "   14. HasFavicon\n",
      "   15. URLCharProb\n"
     ]
    }
   ],
   "source": [
    "# Final Summary - Top 15 Additional Features (compared to Top 10)\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 15 ADDITIONAL FEATURES (5 new features compared to Top 10)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "methods = {\n",
    "    'Boruta': boruta_importance_df,\n",
    "    'RFE': rfe_importance_df,\n",
    "    'Correlation': correlations,\n",
    "    'ContrastFS': contrastfs_df\n",
    "}\n",
    "\n",
    "for method_name, df in methods.items():\n",
    "    top10 = df.head(10)['feature'].tolist()\n",
    "    top15 = df.head(15)['feature'].tolist()\n",
    "    additional_5 = [f for f in top15 if f not in top10]\n",
    "    \n",
    "    print(f\"\\nüìå {method_name} - 5 Additional Features (Rank 11-15):\")\n",
    "    for i, f in enumerate(additional_5, 11):\n",
    "        print(f\"   {i}. {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
